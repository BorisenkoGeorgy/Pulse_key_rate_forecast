{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5caccf16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:31:02.586303Z",
     "iopub.status.busy": "2025-05-04T23:31:02.585468Z",
     "iopub.status.idle": "2025-05-04T23:32:16.121779Z",
     "shell.execute_reply": "2025-05-04T23:32:16.120664Z"
    },
    "papermill": {
     "duration": 73.542971,
     "end_time": "2025-05-04T23:32:16.124446",
     "exception": false,
     "start_time": "2025-05-04T23:31:02.581475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/llama-cpp-wheels/llamacpp\r\n",
      "Processing /kaggle/input/llama-cpp-wheels/llamacpp/llama_cpp_python-0.2.25.tar.gz\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (4.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python) (1.24.3)\r\n",
      "Processing /kaggle/input/llama-cpp-wheels/llamacpp/diskcache-5.6.3-py3-none-any.whl (from llama-cpp-python)\r\n",
      "Building wheels for collected packages: llama-cpp-python\r\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.25-cp310-cp310-manylinux_2_35_x86_64.whl size=8210094 sha256=c2e2acba53fa9b453169ee47e727bfb4a2056eb9f1874cdcef767f9f9b51cc46\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/6d/fa/bb7e80f98dd8f8d64c7ac7e906bbf6bf21ea20de0dfca6039c\r\n",
      "Successfully built llama-cpp-python\r\n",
      "Installing collected packages: diskcache, llama-cpp-python\r\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.25\r\n"
     ]
    }
   ],
   "source": [
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python --no-index --find-links=file:///kaggle/input/llama-cpp-wheels/llamacpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5abfcbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:32:16.135690Z",
     "iopub.status.busy": "2025-05-04T23:32:16.134805Z",
     "iopub.status.idle": "2025-05-04T23:32:16.695286Z",
     "shell.execute_reply": "2025-05-04T23:32:16.694385Z"
    },
    "papermill": {
     "duration": 0.568265,
     "end_time": "2025-05-04T23:32:16.697376",
     "exception": false,
     "start_time": "2025-05-04T23:32:16.129111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570b13e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:32:16.707538Z",
     "iopub.status.busy": "2025-05-04T23:32:16.706920Z",
     "iopub.status.idle": "2025-05-04T23:33:22.195633Z",
     "shell.execute_reply": "2025-05-04T23:33:22.194705Z"
    },
    "papermill": {
     "duration": 65.503593,
     "end_time": "2025-05-04T23:33:22.205449",
     "exception": false,
     "start_time": "2025-05-04T23:32:16.701856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc5cce1ad464d49b11670c3f4bfedfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d677f064379648c296b0b6637c38c5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YandexGPT-5-Lite-8B-instruct.Q8_0.gguf:   0%|          | 0.00/8.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в: /kaggle/working/model\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_name = \"mradermacher/YandexGPT-5-Lite-8B-instruct-GGUF\"  # Пример модели\n",
    "model_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    allow_patterns=[\"*Q8_0.gguf\"],  # Скачивать только нужные файлы\n",
    "    local_dir=\"./model\",\n",
    "    local_dir_use_symlinks=False,\n",
    "    revision=\"main\"  # Ветка репозитория\n",
    ")\n",
    "print(f\"Модель сохранена в: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71bc21d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:33:22.216262Z",
     "iopub.status.busy": "2025-05-04T23:33:22.215476Z",
     "iopub.status.idle": "2025-05-04T23:33:22.221527Z",
     "shell.execute_reply": "2025-05-04T23:33:22.220691Z"
    },
    "papermill": {
     "duration": 0.013216,
     "end_time": "2025-05-04T23:33:22.223228",
     "exception": false,
     "start_time": "2025-05-04T23:33:22.210012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = '''Тебе на вход будет дан комментарий из соц. сети для инвесторов \"Пульс\". Твой задача указать с помощью индексов, относится ли данный комментарий к ключевой ставке ЦБ РФ. В комментарии не обязательно упоминается ЦБ РФ, но под ставкой может все равно подразумеваться ключевая ставка.\n",
    "Также могут быть комментарии, где упоминаются другие ставки, например, ставка оплаты, налоговая ставка, ставки иностранных компаний (в таких постах тогда часто встречается тикер иностранной компании), ставка как в казино. Такие ставки мне неинтересны, надо выделять комментарии именно, где подразумевается ставка ЦБ РФ.\n",
    "Помимо того, что тебе необходимо выделить комментарии про ставку, тебе также необходимо сказать, в какую сторону изменится ставка ЦБ РФ, если об этом сказано в комментарии. Ставка может вырасти, не измениться или снизиться. Однако непосредственно данных слов может не быть в комментарии, возможны варианты.\n",
    "Если по тексту не ясно, в каком направлении изменится ставка, так и напиши.\n",
    "\n",
    "Какие индексы возваращать (то, что должно быть в ответе):\n",
    "Если текст не относится к ставке ЦБ РФ верни число 0. И больше ничего не надо. То есть никакого дополнительного текста.\n",
    "Если текст содержит информацию про ставку ЦБ РФ, в таком случае тебе еще необходимо опеределить направление изменения ставки. Тогда итоговый ответ необходимо представить в формате двух чисел через запятую между ними:\n",
    "1) Первое число — верни 1, так как данный текст про ставку ЦБ РФ.\n",
    "2) Второе число — если говорится, что ставку снизят, то -1, если не изменят, то 0, если повысят, то 1. Если же по тексту нельзя сказать, как изменится ставка, то верни 2.\n",
    "То есть данный комментарий про ставку ЦБ РФ и по нему можно сказать, что автор ожидает повышение ставки ЦБ. Для этого случая от тебя требуется два числа через запятую и больше ничего.\n",
    "Важно: Больше ничего, кроме одного или двух чисел через запятую не возвращай. Не надо пояснять свой ответ, не надо давать дополнительные комментарии, не надо дублировать слова из исходного комментария, нужны просто число или числа и больше ничего.\n",
    "\n",
    "Комментарий:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d219a4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:33:22.233046Z",
     "iopub.status.busy": "2025-05-04T23:33:22.232806Z",
     "iopub.status.idle": "2025-05-04T23:33:22.379255Z",
     "shell.execute_reply": "2025-05-04T23:33:22.378548Z"
    },
    "papermill": {
     "duration": 0.153546,
     "end_time": "2025-05-04T23:33:22.381238",
     "exception": false,
     "start_time": "2025-05-04T23:33:22.227692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "files = [f.replace('.parquet', '') for f in os.listdir('/kaggle/input/dengi-i-credit') if 'retry' in f]\n",
    "for file in files:\n",
    "    dfs[file] = pl.read_parquet(f'/kaggle/input/dengi-i-credit/{file}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26076f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:33:22.391975Z",
     "iopub.status.busy": "2025-05-04T23:33:22.391669Z",
     "iopub.status.idle": "2025-05-04T23:33:22.396906Z",
     "shell.execute_reply": "2025-05-04T23:33:22.396034Z"
    },
    "papermill": {
     "duration": 0.012582,
     "end_time": "2025-05-04T23:33:22.398582",
     "exception": false,
     "start_time": "2025-05-04T23:33:22.386000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# from llama_cpp import Llama\n",
    "# import torch\n",
    "# from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# class GPUTaskWorker:\n",
    "#     def __init__(self, model_path, gpu_id, n_gpu_layers=-1):\n",
    "#         self.gpu_id = gpu_id\n",
    "#         self.model = Llama(\n",
    "#             model_path=model_path,\n",
    "#         \t# repo_id=\"yandex/YandexGPT-5-Lite-8B-instruct-GGUF\",\n",
    "#         \t# filename=\"YandexGPT-5-Lite-8B-instruct-Q4_K_M.gguf\",\n",
    "#             n_gpu_layers=n_gpu_layers,\n",
    "#             n_threads=4,\n",
    "#             n_ctx=1024,\n",
    "#             main_gpu=gpu_id,\n",
    "#         )\n",
    "#         # print(f\"Модель на GPU {gpu_id} использует {self.model._model.n_gpu_layers()} слоёв на GPU\")\n",
    "#         self.queue = asyncio.Queue()\n",
    "#         self.is_working = False\n",
    "\n",
    "#     async def process_queue(self):\n",
    "#         while True:\n",
    "#             prompt, future = await self.queue.get()\n",
    "#             self.is_working = True\n",
    "#             try:\n",
    "#                 result = await asyncio.get_event_loop().run_in_executor(\n",
    "#                     None,\n",
    "#                     lambda: self.model(prompt, max_tokens=16)\n",
    "#                 )\n",
    "#                 future.set_result((self.gpu_id, result))\n",
    "#             except Exception as e:\n",
    "#                 future.set_exception(e)\n",
    "#             finally:\n",
    "#                 self.is_working = False\n",
    "#                 self.queue.task_done()\n",
    "\n",
    "# class MultiGPULlamaDispatcher:\n",
    "#     def __init__(self, model_path, n_gpus=-1, n_gpu_layers=-1):\n",
    "#         self.model_path = model_path\n",
    "#         self.n_gpus = n_gpus if n_gpus > 0 else torch.cuda.device_count()\n",
    "#         self.n_gpu_layers = n_gpu_layers\n",
    "#         self.workers = []\n",
    "#         self.loop = asyncio.get_event_loop()\n",
    "        \n",
    "#     async def initialize(self):\n",
    "#         # Инициализация воркеров для каждого GPU\n",
    "#         for gpu_id in range(self.n_gpus):\n",
    "#             worker = GPUTaskWorker(self.model_path, gpu_id, self.n_gpu_layers)\n",
    "#             self.workers.append(worker)\n",
    "#             # Запускаем обработчик очереди для каждого воркера\n",
    "#             asyncio.create_task(worker.process_queue())\n",
    "    \n",
    "#     async def dispatch_prompt(self, prompt):\n",
    "#         # Находим наименее загруженный GPU\n",
    "#         available_workers = [w for w in self.workers if not w.is_working]\n",
    "#         if not available_workers:\n",
    "#             # Если все заняты, выбираем тот, у которого самая короткая очередь\n",
    "#             worker = min(self.workers, key=lambda w: w.queue.qsize())\n",
    "#         else:\n",
    "#             worker = available_workers[0]\n",
    "        \n",
    "#         future = self.loop.create_future()\n",
    "#         await worker.queue.put((prompt, future))\n",
    "#         return future\n",
    "    \n",
    "#     async def dispatch_prompts(self, prompts):\n",
    "#         tasks = [self.dispatch_prompt(prompt) for prompt in prompts]\n",
    "#         return await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca5e9e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:33:22.409412Z",
     "iopub.status.busy": "2025-05-04T23:33:22.409113Z",
     "iopub.status.idle": "2025-05-04T23:33:22.413451Z",
     "shell.execute_reply": "2025-05-04T23:33:22.412563Z"
    },
    "papermill": {
     "duration": 0.012222,
     "end_time": "2025-05-04T23:33:22.415346",
     "exception": false,
     "start_time": "2025-05-04T23:33:22.403124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_path = '/kaggle/working/model'\n",
    "# model_path = model_path + '/YandexGPT-5-Lite-8B-instruct-Q4_K_M.gguf'\n",
    "# dispatcher = MultiGPULlamaDispatcher(model_path, n_gpus=2)\n",
    "# await dispatcher.initialize()\n",
    "\n",
    "# all_results = []\n",
    "\n",
    "# for key in dfs:\n",
    "#     responses = []\n",
    "#     reasons = []\n",
    "#     prompts = [prompt + message for message in dfs[key][key].to_list()[: 4]]\n",
    "    \n",
    "#     print(f\"Начали обработку {len(prompts)} промптов на {dispatcher.n_gpus} GPU...\")\n",
    "    \n",
    "#     results = await dispatcher.dispatch_prompts(prompts)\n",
    "    \n",
    "#     for result in results:\n",
    "#         responses.append(result.result()[1]['choices'][0]['text'].strip())\n",
    "#         reasons.append(result.result()[1]['choices'][0]['finish_reason'])\n",
    "#     dfs[key] = dfs[key].wirh_columns(responses=responses, reasons=reasons)\n",
    "#     dfs[key].write_parquet(f'{key}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e7b95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:33:22.426796Z",
     "iopub.status.busy": "2025-05-04T23:33:22.426115Z",
     "iopub.status.idle": "2025-05-04T23:33:26.597330Z",
     "shell.execute_reply": "2025-05-04T23:33:26.596384Z"
    },
    "papermill": {
     "duration": 4.178837,
     "end_time": "2025-05-04T23:33:26.599221",
     "exception": false,
     "start_time": "2025-05-04T23:33:22.420384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: Tesla P100-PCIE-16GB, compute capability 6.0\n",
      "llama_model_loader: loaded meta data with 44 key-value pairs and 291 tensors from /kaggle/working/model/YandexGPT-5-Lite-8B-instruct.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = YandexGPT 5 Lite 8B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = YandexGPT-5-Lite\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                            general.license str              = other\n",
      "llama_model_loader: - kv   7:                       general.license.name str              = yandexgpt-5-lite-8b\n",
      "llama_model_loader: - kv   8:                       general.license.link str              = LICENSE\n",
      "llama_model_loader: - kv   9:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv  10:                  general.base_model.0.name str              = YandexGPT 5 Lite 8B Pretrain\n",
      "llama_model_loader: - kv  11:          general.base_model.0.organization str              = Yandex\n",
      "llama_model_loader: - kv  12:              general.base_model.0.repo_url str              = https://huggingface.co/yandex/YandexG...\n",
      "llama_model_loader: - kv  13:                          general.languages arr[str,2]       = [\"ru\", \"en\"]\n",
      "llama_model_loader: - kv  14:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv  15:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv  16:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  17:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  18:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  19:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  20:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  21:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  22:                           llama.vocab_size u32              = 129024\n",
      "llama_model_loader: - kv  23:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  24:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  25:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.tokens arr[str,129024]  = [\"<unk>\", \"<s>\", \"</s>\", \"\\n\", \"[SEP]\"...\n",
      "llama_model_loader: - kv  27:                      tokenizer.ggml.scores arr[f32,129024]  = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  28:                  tokenizer.ggml.token_type arr[i32,129024]  = [3, 3, 3, 1, 4, 4, 4, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  31:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  32:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  33:                    tokenizer.chat_template str              = <s>{%- set names = {'assistant': ' А...\n",
      "llama_model_loader: - kv  34:            tokenizer.ggml.add_space_prefix bool             = true\n",
      "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  36:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  37:                                general.url str              = https://huggingface.co/mradermacher/Y...\n",
      "llama_model_loader: - kv  38:              mradermacher.quantize_version str              = 2\n",
      "llama_model_loader: - kv  39:                  mradermacher.quantized_by str              = mradermacher\n",
      "llama_model_loader: - kv  40:                  mradermacher.quantized_at str              = 2025-03-31T18:10:17+02:00\n",
      "llama_model_loader: - kv  41:                  mradermacher.quantized_on str              = marco\n",
      "llama_model_loader: - kv  42:                         general.source.url str              = https://huggingface.co/yandex/YandexG...\n",
      "llama_model_loader: - kv  43:                  mradermacher.convert_type str              = hf\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 1286/129024 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 129024\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 8.04 B\n",
      "llm_load_print_meta: model size       = 7.95 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = YandexGPT 5 Lite 8B Instruct\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 17 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: system memory used  =  535.61 MiB\n",
      "llm_load_tensors: VRAM used           = 7608.52 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 291.19 MiB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 288.00 MiB\n",
      "llama_new_context_with_model: total VRAM used: 7896.52 MiB (model: 7608.52 MiB, context: 288.00 MiB)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "model_path = '/kaggle/working/model'\n",
    "model_path = model_path + '/YandexGPT-5-Lite-8B-instruct.Q8_0.gguf'\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_gpu_layers=-1,\n",
    "    n_threads=4,\n",
    "    n_ctx=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742e2392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T23:33:26.611557Z",
     "iopub.status.busy": "2025-05-04T23:33:26.610850Z",
     "iopub.status.idle": "2025-05-05T00:00:57.700624Z",
     "shell.execute_reply": "2025-05-05T00:00:57.698844Z"
    },
    "papermill": {
     "duration": 1651.099192,
     "end_time": "2025-05-05T00:00:57.703958",
     "exception": false,
     "start_time": "2025-05-04T23:33:26.604766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:11<03:46, 11.91s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     120.54 ms /    60 runs   (    2.01 ms per token,   497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5158.98 ms /   454 tokens (   11.36 ms per token,    88.00 tokens per second)\n",
      "llama_print_timings:        eval time =    5953.64 ms /    59 runs   (  100.91 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =   11904.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 10%|█         | 2/20 [00:13<01:43,  5.75s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      15.55 ms /     8 runs   (    1.94 ms per token,   514.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.55 ms /    41 tokens (   15.50 ms per token,    64.51 tokens per second)\n",
      "llama_print_timings:        eval time =     699.20 ms /     7 runs   (   99.89 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =    1425.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 15%|█▌        | 3/20 [00:21<01:57,  6.89s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     135.93 ms /    67 runs   (    2.03 ms per token,   492.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.64 ms /    52 tokens (   13.38 ms per token,    74.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6796.32 ms /    66 runs   (  102.97 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    8249.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 20%|██        | 4/20 [00:33<02:19,  8.70s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     168.33 ms /    93 runs   (    1.81 ms per token,   552.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.96 ms /    66 tokens (   13.97 ms per token,    71.59 tokens per second)\n",
      "llama_print_timings:        eval time =    9511.90 ms /    92 runs   (  103.39 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =   11466.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 25%|██▌       | 5/20 [00:36<01:41,  6.77s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.76 ms /    21 runs   (    2.04 ms per token,   491.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.24 ms /    86 tokens (   12.24 ms per token,    81.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2053.66 ms /    20 runs   (  102.68 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    3338.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 30%|███       | 6/20 [00:38<01:13,  5.22s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.15 ms /    11 runs   (    1.92 ms per token,   520.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.58 ms /    88 tokens (   12.06 ms per token,    82.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1021.63 ms /    10 runs   (  102.16 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    2202.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 35%|███▌      | 7/20 [00:40<00:52,  4.06s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.51 ms /    12 runs   (    1.96 ms per token,   510.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.03 ms /    11 tokens (   42.09 ms per token,    23.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1089.34 ms /    11 runs   (   99.03 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    1685.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 40%|████      | 8/20 [00:42<00:43,  3.59s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       9.91 ms /     5 runs   (    1.98 ms per token,   504.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2102.64 ms /   205 tokens (   10.26 ms per token,    97.50 tokens per second)\n",
      "llama_print_timings:        eval time =     424.58 ms /     4 runs   (  106.14 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    2583.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 45%|████▌     | 9/20 [00:47<00:42,  3.86s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      65.45 ms /    34 runs   (    1.93 ms per token,   519.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     759.29 ms /    26 tokens (   29.20 ms per token,    34.24 tokens per second)\n",
      "llama_print_timings:        eval time =    3311.36 ms /    33 runs   (  100.34 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    4443.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|█████     | 10/20 [00:49<00:33,  3.32s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.82 ms /    14 runs   (    1.99 ms per token,   503.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.80 ms /    45 tokens (   14.48 ms per token,    69.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1311.76 ms /    13 runs   (  100.90 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    2117.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 55%|█████▌    | 11/20 [00:52<00:28,  3.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.03 ms /    19 runs   (    2.00 ms per token,   499.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.76 ms /    24 tokens (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1805.48 ms /    18 runs   (  100.30 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    2741.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 60%|██████    | 12/20 [00:53<00:20,  2.57s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /     6 runs   (    1.95 ms per token,   512.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.75 ms /    44 tokens (   15.02 ms per token,    66.59 tokens per second)\n",
      "llama_print_timings:        eval time =     499.59 ms /     5 runs   (   99.92 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =    1234.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 65%|██████▌   | 13/20 [00:55<00:17,  2.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.77 ms /    13 runs   (    1.75 ms per token,   570.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.86 ms /    64 tokens (   12.37 ms per token,    80.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.74 ms /    12 runs   (  101.06 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    2145.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 70%|███████   | 14/20 [00:59<00:16,  2.74s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      45.05 ms /    22 runs   (    2.05 ms per token,   488.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.48 ms /    85 tokens (   12.23 ms per token,    81.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2145.93 ms /    21 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    3429.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 75%|███████▌  | 15/20 [01:01<00:13,  2.61s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      13.95 ms /     7 runs   (    1.99 ms per token,   501.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1575.87 ms /   139 tokens (   11.34 ms per token,    88.21 tokens per second)\n",
      "llama_print_timings:        eval time =     631.35 ms /     6 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2285.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 80%|████████  | 16/20 [01:03<00:09,  2.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.82 ms /    12 runs   (    1.99 ms per token,   503.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     480.31 ms /    12 tokens (   40.03 ms per token,    24.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1085.45 ms /    11 runs   (   98.68 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    1697.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 85%|████████▌ | 17/20 [01:06<00:07,  2.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      40.31 ms /    20 runs   (    2.02 ms per token,   496.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     910.45 ms /    65 tokens (   14.01 ms per token,    71.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1931.42 ms /    19 runs   (  101.65 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    3063.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 90%|█████████ | 18/20 [01:14<00:08,  4.29s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     126.84 ms /    68 runs   (    1.87 ms per token,   536.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.50 ms /    52 tokens (   13.53 ms per token,    73.92 tokens per second)\n",
      "llama_print_timings:        eval time =    6856.55 ms /    67 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    8309.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 95%|█████████▌| 19/20 [01:15<00:03,  3.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.64 ms /     9 runs   (    1.96 ms per token,   510.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     575.07 ms /    17 tokens (   33.83 ms per token,    29.56 tokens per second)\n",
      "llama_print_timings:        eval time =     799.94 ms /     8 runs   (   99.99 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    1474.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "100%|██████████| 20/20 [01:16<00:00,  2.69s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     1 runs   (    2.05 ms per token,   487.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     923.49 ms /    67 tokens (   13.78 ms per token,    72.55 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =     935.23 ms\n",
      "100%|██████████| 20/20 [01:16<00:00,  3.84s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      " 11%|█         | 1/9 [00:01<00:12,  1.53s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.20 ms /     9 runs   (    2.02 ms per token,   494.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.40 ms /    36 tokens (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_print_timings:        eval time =     818.27 ms /     8 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1526.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 22%|██▏       | 2/9 [00:02<00:07,  1.07s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /     2 runs   (    2.09 ms per token,   478.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.44 ms /    36 tokens (   16.98 ms per token,    58.88 tokens per second)\n",
      "llama_print_timings:        eval time =     102.78 ms /     1 runs   (  102.78 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =     736.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 33%|███▎      | 3/9 [00:04<00:09,  1.61s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      36.30 ms /    17 runs   (    2.14 ms per token,   468.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     407.46 ms /     7 tokens (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1635.43 ms /    16 runs   (  102.21 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    2241.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▍     | 4/9 [00:08<00:13,  2.73s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      66.97 ms /    33 runs   (    2.03 ms per token,   492.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.19 ms /    52 tokens (   13.91 ms per token,    71.90 tokens per second)\n",
      "llama_print_timings:        eval time =    3347.21 ms /    32 runs   (  104.60 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    4448.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▌    | 5/9 [00:09<00:08,  2.03s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /     2 runs   (    2.10 ms per token,   475.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.79 ms /    41 tokens (   15.75 ms per token,    63.49 tokens per second)\n",
      "llama_print_timings:        eval time =     102.03 ms /     1 runs   (  102.03 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =     770.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 67%|██████▋   | 6/9 [00:10<00:04,  1.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     2 runs   (    2.12 ms per token,   472.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.12 ms /    53 tokens (   13.76 ms per token,    72.69 tokens per second)\n",
      "llama_print_timings:        eval time =     103.38 ms /     1 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =     855.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 78%|███████▊  | 7/9 [00:12<00:03,  1.65s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.46 ms /    10 runs   (    2.05 ms per token,   488.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.63 ms /    19 tokens (   35.09 ms per token,    28.50 tokens per second)\n",
      "llama_print_timings:        eval time =     917.48 ms /     9 runs   (  101.94 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1694.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 89%|████████▉ | 8/9 [00:13<00:01,  1.65s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.90 ms /    10 runs   (    2.09 ms per token,   478.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.81 ms /    36 tokens (   16.97 ms per token,    58.94 tokens per second)\n",
      "llama_print_timings:        eval time =     920.87 ms /     9 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1642.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "100%|██████████| 9/9 [00:16<00:00,  1.93s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.52 ms /    17 runs   (    2.03 ms per token,   492.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.73 ms /    47 tokens (   15.02 ms per token,    66.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1654.60 ms /    16 runs   (  103.41 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    2550.73 ms\n",
      "100%|██████████| 9/9 [00:16<00:00,  1.83s/it]\n",
      "  0%|          | 0/317 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "  0%|          | 1/317 [00:02<10:46,  2.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.28 ms /    14 runs   (    2.02 ms per token,   495.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     536.44 ms /    12 tokens (   44.70 ms per token,    22.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1348.25 ms /    13 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2040.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  1%|          | 2/317 [00:03<09:36,  1.83s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.36 ms /    10 runs   (    2.04 ms per token,   491.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.67 ms /    34 tokens (   18.14 ms per token,    55.14 tokens per second)\n",
      "llama_print_timings:        eval time =     944.21 ms /     9 runs   (  104.91 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1672.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  1%|          | 3/317 [00:07<13:07,  2.51s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      48.03 ms /    23 runs   (    2.09 ms per token,   478.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.76 ms /    51 tokens (   14.29 ms per token,    69.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2320.09 ms /    22 runs   (  105.46 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    3308.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  1%|▏         | 4/317 [00:08<11:28,  2.20s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.32 ms /    11 runs   (    2.03 ms per token,   492.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     537.18 ms /    32 tokens (   16.79 ms per token,    59.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1060.23 ms /    10 runs   (  106.02 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1719.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  2%|▏         | 5/317 [00:11<11:56,  2.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.31 ms /    11 runs   (    2.03 ms per token,   493.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1263.83 ms /   104 tokens (   12.15 ms per token,    82.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1076.92 ms /    10 runs   (  107.69 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    2464.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  2%|▏         | 6/317 [00:13<11:04,  2.14s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.45 ms /    11 runs   (    1.95 ms per token,   512.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.82 ms /    39 tokens (   16.69 ms per token,    59.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1042.61 ms /    10 runs   (  104.26 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1816.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  2%|▏         | 7/317 [00:15<10:50,  2.10s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.88 ms /    12 runs   (    1.99 ms per token,   502.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.83 ms /    22 tokens (   34.04 ms per token,    29.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.17 ms /    11 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2021.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  3%|▎         | 8/317 [00:16<10:11,  1.98s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.82 ms /    11 runs   (    2.07 ms per token,   482.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     539.73 ms /    32 tokens (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.98 ms /    10 runs   (  105.00 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1712.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  3%|▎         | 9/317 [00:19<10:55,  2.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.14 ms /    16 runs   (    2.07 ms per token,   482.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.15 ms /    20 tokens (   35.21 ms per token,    28.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1561.75 ms /    15 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2450.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  3%|▎         | 10/317 [00:24<15:15,  2.98s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      76.50 ms /    37 runs   (    2.07 ms per token,   483.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.80 ms /    39 tokens (   16.71 ms per token,    59.83 tokens per second)\n",
      "llama_print_timings:        eval time =    3810.96 ms /    36 runs   (  105.86 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    4887.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  3%|▎         | 11/317 [00:26<13:40,  2.68s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.86 ms /    10 runs   (    1.89 ms per token,   530.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     938.24 ms /    30 tokens (   31.27 ms per token,    31.97 tokens per second)\n",
      "llama_print_timings:        eval time =     950.24 ms /     9 runs   (  105.58 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2000.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  4%|▍         | 12/317 [00:28<12:31,  2.46s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.77 ms /    11 runs   (    2.07 ms per token,   483.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.58 ms /    24 tokens (   32.90 ms per token,    30.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1042.98 ms /    10 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1957.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  4%|▍         | 13/317 [00:29<10:58,  2.17s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /     9 runs   (    1.94 ms per token,   516.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     538.50 ms /    32 tokens (   16.83 ms per token,    59.42 tokens per second)\n",
      "llama_print_timings:        eval time =     837.15 ms /     8 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    1475.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  4%|▍         | 14/317 [00:31<11:01,  2.18s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.81 ms /    11 runs   (    1.80 ms per token,   555.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.22 ms /    74 tokens (   13.92 ms per token,    71.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1067.21 ms /    10 runs   (  106.72 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    2220.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  5%|▍         | 15/317 [00:34<11:00,  2.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      16.79 ms /    10 runs   (    1.68 ms per token,   595.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.34 ms /    85 tokens (   13.16 ms per token,    76.01 tokens per second)\n",
      "llama_print_timings:        eval time =     960.47 ms /     9 runs   (  106.72 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    2188.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  5%|▌         | 16/317 [00:36<11:22,  2.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.68 ms /    15 runs   (    2.05 ms per token,   488.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.72 ms /    59 tokens (   13.28 ms per token,    75.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1490.25 ms /    14 runs   (  106.45 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    2442.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  5%|▌         | 17/317 [00:38<10:43,  2.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.59 ms /    11 runs   (    2.05 ms per token,   486.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.96 ms /    42 tokens (   16.02 ms per token,    62.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1060.10 ms /    10 runs   (  106.01 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1859.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  6%|▌         | 18/317 [00:40<10:16,  2.06s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.25 ms /     9 runs   (    2.03 ms per token,   493.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     927.18 ms /    28 tokens (   33.11 ms per token,    30.20 tokens per second)\n",
      "llama_print_timings:        eval time =     839.63 ms /     8 runs   (  104.95 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1867.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  6%|▌         | 19/317 [00:43<11:24,  2.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.14 ms /    20 runs   (    2.11 ms per token,   474.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.92 ms /    33 tokens (   18.45 ms per token,    54.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1999.61 ms /    19 runs   (  105.24 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2834.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  6%|▋         | 20/317 [00:44<10:03,  2.03s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.07 ms /     9 runs   (    2.01 ms per token,   498.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     486.49 ms /    10 tokens (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_print_timings:        eval time =     827.90 ms /     8 runs   (  103.49 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1414.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  7%|▋         | 21/317 [00:47<10:56,  2.22s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.64 ms /    19 runs   (    2.03 ms per token,   491.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     537.11 ms /    32 tokens (   16.78 ms per token,    59.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1888.65 ms /    18 runs   (  104.92 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    2637.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  7%|▋         | 22/317 [00:49<10:29,  2.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.43 ms /    11 runs   (    1.95 ms per token,   513.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     745.15 ms /    53 tokens (   14.06 ms per token,    71.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1056.13 ms /    10 runs   (  105.61 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    1931.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  7%|▋         | 23/317 [00:50<09:54,  2.02s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.94 ms /    11 runs   (    1.99 ms per token,   501.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.58 ms /    15 tokens (   39.91 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1038.95 ms /    10 runs   (  103.90 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1763.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  8%|▊         | 24/317 [00:55<14:05,  2.89s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      68.94 ms /    35 runs   (    1.97 ms per token,   507.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     905.88 ms /    29 tokens (   31.24 ms per token,    32.01 tokens per second)\n",
      "llama_print_timings:        eval time =    3586.49 ms /    34 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    4890.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  8%|▊         | 25/317 [00:57<12:46,  2.62s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.54 ms /    12 runs   (    2.04 ms per token,   489.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.82 ms /    49 tokens (   14.61 ms per token,    68.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.98 ms /    11 runs   (  105.18 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2007.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  8%|▊         | 26/317 [00:58<10:37,  2.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.29 ms /    10 runs   (    2.03 ms per token,   492.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1053.30 ms /    10 runs   (  105.33 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1169.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  9%|▊         | 27/317 [01:00<09:26,  1.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.28 ms /    12 runs   (    2.02 ms per token,   494.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1259.97 ms /    12 runs   (  105.00 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1393.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  9%|▉         | 28/317 [01:04<13:13,  2.74s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      71.07 ms /    34 runs   (    2.09 ms per token,   478.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.27 ms /    22 tokens (   34.06 ms per token,    29.36 tokens per second)\n",
      "llama_print_timings:        eval time =    3455.88 ms /    33 runs   (  104.72 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    4587.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  9%|▉         | 29/317 [01:09<15:43,  3.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      65.40 ms /    32 runs   (    2.04 ms per token,   489.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.33 ms /    64 tokens (   13.19 ms per token,    75.80 tokens per second)\n",
      "llama_print_timings:        eval time =    3296.74 ms /    31 runs   (  106.35 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    4506.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  9%|▉         | 30/317 [01:11<14:05,  2.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.57 ms /    11 runs   (    2.05 ms per token,   487.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.71 ms /    67 tokens (   14.77 ms per token,    67.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1065.76 ms /    10 runs   (  106.58 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    2178.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 10%|▉         | 31/317 [01:13<12:16,  2.57s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.18 ms /    10 runs   (    2.02 ms per token,   495.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.12 ms /    17 tokens (   38.24 ms per token,    26.15 tokens per second)\n",
      "llama_print_timings:        eval time =     935.72 ms /     9 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1696.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 10%|█         | 32/317 [01:14<10:54,  2.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.06 ms /    11 runs   (    2.01 ms per token,   498.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     488.53 ms /    10 tokens (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1033.52 ms /    10 runs   (  103.35 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1643.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 10%|█         | 33/317 [01:16<10:10,  2.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.13 ms /    10 runs   (    2.11 ms per token,   473.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.44 ms /    22 tokens (   34.20 ms per token,    29.24 tokens per second)\n",
      "llama_print_timings:        eval time =     936.07 ms /     9 runs   (  104.01 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1801.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 11%|█         | 34/317 [01:18<09:25,  2.00s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.47 ms /    10 runs   (    2.05 ms per token,   488.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.72 ms /    15 tokens (   39.51 ms per token,    25.31 tokens per second)\n",
      "llama_print_timings:        eval time =     937.51 ms /     9 runs   (  104.17 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1642.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 11%|█         | 35/317 [01:20<10:05,  2.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.48 ms /    16 runs   (    2.09 ms per token,   477.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.00 ms /    22 tokens (   33.82 ms per token,    29.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1563.32 ms /    15 runs   (  104.22 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    2488.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 11%|█▏        | 36/317 [01:22<09:23,  2.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.91 ms /    10 runs   (    1.99 ms per token,   502.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.76 ms /    34 tokens (   18.11 ms per token,    55.22 tokens per second)\n",
      "llama_print_timings:        eval time =     943.81 ms /     9 runs   (  104.87 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1671.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 12%|█▏        | 37/317 [01:24<09:05,  1.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.45 ms /    11 runs   (    2.04 ms per token,   489.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.37 ms /    37 tokens (   17.23 ms per token,    58.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1050.48 ms /    10 runs   (  105.05 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1811.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 12%|█▏        | 38/317 [01:26<08:54,  1.92s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.73 ms /    11 runs   (    1.98 ms per token,   506.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.17 ms /    38 tokens (   16.95 ms per token,    58.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1054.15 ms /    10 runs   (  105.42 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1828.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 12%|█▏        | 39/317 [01:27<08:40,  1.87s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.01 ms /     9 runs   (    2.11 ms per token,   473.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     819.68 ms /    23 tokens (   35.64 ms per token,    28.06 tokens per second)\n",
      "llama_print_timings:        eval time =     837.58 ms /     8 runs   (  104.70 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1765.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 13%|█▎        | 40/317 [01:30<09:15,  2.00s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.29 ms /    15 runs   (    2.02 ms per token,   495.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.37 ms /    19 tokens (   36.18 ms per token,    27.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1450.92 ms /    14 runs   (  103.64 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2305.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 13%|█▎        | 41/317 [01:32<09:07,  1.98s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.35 ms /    12 runs   (    2.03 ms per token,   492.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.27 ms /    38 tokens (   16.93 ms per token,    59.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.43 ms /    11 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1925.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 13%|█▎        | 42/317 [01:33<08:43,  1.90s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.64 ms /     9 runs   (    1.96 ms per token,   510.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.57 ms /    58 tokens (   13.34 ms per token,    74.98 tokens per second)\n",
      "llama_print_timings:        eval time =     844.08 ms /     8 runs   (  105.51 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    1717.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 14%|█▎        | 43/317 [01:35<08:45,  1.92s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.81 ms /    11 runs   (    2.07 ms per token,   482.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.98 ms /    23 tokens (   33.78 ms per token,    29.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1047.07 ms /    10 runs   (  104.71 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1947.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 14%|█▍        | 44/317 [01:37<08:43,  1.92s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.58 ms /    11 runs   (    1.96 ms per token,   509.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.38 ms /    52 tokens (   14.10 ms per token,    70.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1048.02 ms /    10 runs   (  104.80 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1903.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 14%|█▍        | 45/317 [01:40<09:52,  2.18s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      36.74 ms /    19 runs   (    1.93 ms per token,   517.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.87 ms /    44 tokens (   15.75 ms per token,    63.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1884.60 ms /    18 runs   (  104.70 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2788.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 15%|█▍        | 46/317 [01:45<14:03,  3.11s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      80.72 ms /    39 runs   (    2.07 ms per token,   483.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     858.66 ms /    27 tokens (   31.80 ms per token,    31.44 tokens per second)\n",
      "llama_print_timings:        eval time =    3987.52 ms /    38 runs   (  104.93 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    5287.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 15%|█▍        | 47/317 [01:49<14:17,  3.17s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      50.36 ms /    25 runs   (    2.01 ms per token,   496.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     530.54 ms /    12 tokens (   44.21 ms per token,    22.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2497.99 ms /    24 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    3309.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 15%|█▌        | 48/317 [01:50<12:07,  2.71s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.42 ms /    10 runs   (    2.04 ms per token,   489.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     550.32 ms /    13 tokens (   42.33 ms per token,    23.62 tokens per second)\n",
      "llama_print_timings:        eval time =     939.87 ms /     9 runs   (  104.43 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1604.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 15%|█▌        | 49/317 [01:52<10:57,  2.45s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.09 ms /    10 runs   (    1.81 ms per token,   552.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     795.79 ms /    61 tokens (   13.05 ms per token,    76.65 tokens per second)\n",
      "llama_print_timings:        eval time =     956.38 ms /     9 runs   (  106.27 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    1862.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 16%|█▌        | 50/317 [01:56<13:08,  2.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      63.93 ms /    31 runs   (    2.06 ms per token,   484.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.13 ms /    17 tokens (   37.71 ms per token,    26.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3120.85 ms /    30 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    4109.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 16%|█▌        | 51/317 [02:00<13:41,  3.09s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      59.72 ms /    29 runs   (    2.06 ms per token,   485.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    3057.00 ms /    29 runs   (  105.41 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    3399.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 16%|█▋        | 52/317 [02:02<11:55,  2.70s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.87 ms /    11 runs   (    2.08 ms per token,   481.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.45 ms /    16 tokens (   39.59 ms per token,    25.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1036.69 ms /    10 runs   (  103.67 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1794.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 17%|█▋        | 53/317 [02:04<11:50,  2.69s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.07 ms /    12 runs   (    2.01 ms per token,   498.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.75 ms /   115 tokens (   11.68 ms per token,    85.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.51 ms /    11 runs   (  107.50 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =    2661.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 17%|█▋        | 54/317 [02:06<11:03,  2.52s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.64 ms /    10 runs   (    1.86 ms per token,   536.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.88 ms /    75 tokens (   14.05 ms per token,    71.17 tokens per second)\n",
      "llama_print_timings:        eval time =     957.96 ms /     9 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    2123.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 17%|█▋        | 55/317 [02:09<11:20,  2.60s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.12 ms /    19 runs   (    2.01 ms per token,   498.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.14 ms /    40 tokens (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1893.65 ms /    18 runs   (  105.20 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2769.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 18%|█▊        | 56/317 [02:12<11:05,  2.55s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.69 ms /    10 runs   (    2.07 ms per token,   483.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1343.83 ms /   116 tokens (   11.58 ms per token,    86.32 tokens per second)\n",
      "llama_print_timings:        eval time =     970.03 ms /     9 runs   (  107.78 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    2427.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 18%|█▊        | 57/317 [02:17<14:26,  3.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      74.63 ms /    37 runs   (    2.02 ms per token,   495.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     949.78 ms /    31 tokens (   30.64 ms per token,    32.64 tokens per second)\n",
      "llama_print_timings:        eval time =    3787.32 ms /    36 runs   (  105.20 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    5154.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 18%|█▊        | 58/317 [02:21<15:20,  3.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      57.80 ms /    30 runs   (    1.93 ms per token,   519.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.24 ms /    43 tokens (   15.68 ms per token,    63.78 tokens per second)\n",
      "llama_print_timings:        eval time =    3054.74 ms /    29 runs   (  105.34 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    4068.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 19%|█▊        | 59/317 [02:23<12:57,  3.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.42 ms /    10 runs   (    2.04 ms per token,   489.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.69 ms /    20 tokens (   35.43 ms per token,    28.22 tokens per second)\n",
      "llama_print_timings:        eval time =     926.66 ms /     9 runs   (  102.96 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1746.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 19%|█▉        | 60/317 [02:24<11:12,  2.62s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.52 ms /    10 runs   (    2.05 ms per token,   487.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.12 ms /    36 tokens (   17.50 ms per token,    57.13 tokens per second)\n",
      "llama_print_timings:        eval time =     945.85 ms /     9 runs   (  105.09 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1688.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 19%|█▉        | 61/317 [02:27<10:46,  2.53s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.34 ms /    13 runs   (    2.03 ms per token,   493.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     904.98 ms /    29 tokens (   31.21 ms per token,    32.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1257.35 ms /    12 runs   (  104.78 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    2308.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 20%|█▉        | 62/317 [02:30<12:04,  2.84s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.32 ms /    11 runs   (    2.03 ms per token,   492.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2307.91 ms /   208 tokens (   11.10 ms per token,    90.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.02 ms /    10 runs   (  113.30 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    3569.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 20%|█▉        | 63/317 [02:32<10:48,  2.55s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.48 ms /    11 runs   (    2.04 ms per token,   489.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.82 ms /    45 tokens (   15.44 ms per token,    64.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.23 ms /    10 runs   (  104.92 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1868.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 20%|██        | 64/317 [02:39<16:40,  3.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     118.42 ms /    56 runs   (    2.11 ms per token,   472.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.74 ms /    22 tokens (   33.85 ms per token,    29.54 tokens per second)\n",
      "llama_print_timings:        eval time =    5826.33 ms /    55 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    7215.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 21%|██        | 65/317 [02:42<14:44,  3.51s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.61 ms /    12 runs   (    1.97 ms per token,   508.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.06 ms /    91 tokens (   12.67 ms per token,    78.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1177.86 ms /    11 runs   (  107.08 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    2466.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 21%|██        | 66/317 [02:44<12:53,  3.08s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      13.86 ms /     8 runs   (    1.73 ms per token,   577.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1238.72 ms /   101 tokens (   12.26 ms per token,    81.54 tokens per second)\n",
      "llama_print_timings:        eval time =     750.79 ms /     7 runs   (  107.26 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    2079.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 21%|██        | 67/317 [02:46<11:12,  2.69s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.79 ms /    10 runs   (    2.08 ms per token,   481.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.11 ms /    20 tokens (   35.76 ms per token,    27.97 tokens per second)\n",
      "llama_print_timings:        eval time =     937.92 ms /     9 runs   (  104.21 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1766.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 21%|██▏       | 68/317 [02:49<12:06,  2.92s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      47.87 ms /    23 runs   (    2.08 ms per token,   480.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     865.66 ms /    27 tokens (   32.06 ms per token,    31.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2320.20 ms /    22 runs   (  105.46 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    3450.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 22%|██▏       | 69/317 [02:51<10:45,  2.60s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.13 ms /    10 runs   (    2.01 ms per token,   496.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     796.69 ms /    60 tokens (   13.28 ms per token,    75.31 tokens per second)\n",
      "llama_print_timings:        eval time =     954.24 ms /     9 runs   (  106.03 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1863.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 22%|██▏       | 70/317 [02:55<12:24,  3.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.36 ms /    15 runs   (    2.09 ms per token,   478.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2227.91 ms /   200 tokens (   11.14 ms per token,    89.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1566.03 ms /    14 runs   (  111.86 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =    3966.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.45 ms /    16 runs   (    2.09 ms per token,   478.27 tokens per second)\n",
      " 22%|██▏       | 71/317 [02:57<11:33,  2.82s/it]llama_print_timings: prompt eval time =     618.57 ms /    16 tokens (   38.66 ms per token,    25.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1553.15 ms /    15 runs   (  103.54 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2358.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 23%|██▎       | 72/317 [02:59<10:10,  2.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.98 ms /    11 runs   (    2.00 ms per token,   500.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     559.62 ms /    13 tokens (   43.05 ms per token,    23.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1032.85 ms /    10 runs   (  103.29 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1716.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 23%|██▎       | 73/317 [03:01<09:40,  2.38s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.86 ms /    13 runs   (    2.07 ms per token,   483.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.38 ms /    47 tokens (   14.97 ms per token,    66.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1260.21 ms /    12 runs   (  105.02 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    2110.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 23%|██▎       | 74/317 [03:03<08:55,  2.20s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.86 ms /     9 runs   (    2.10 ms per token,   477.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.80 ms /    25 tokens (   34.31 ms per token,    29.14 tokens per second)\n",
      "llama_print_timings:        eval time =     831.64 ms /     8 runs   (  103.95 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1790.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 24%|██▎       | 75/317 [03:07<11:26,  2.84s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      64.55 ms /    31 runs   (    2.08 ms per token,   480.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.41 ms /    57 tokens (   13.48 ms per token,    74.18 tokens per second)\n",
      "llama_print_timings:        eval time =    3182.56 ms /    30 runs   (  106.09 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    4303.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 24%|██▍       | 76/317 [03:16<19:05,  4.75s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     132.76 ms /    68 runs   (    1.95 ms per token,   512.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.57 ms /    93 tokens (   12.61 ms per token,    79.31 tokens per second)\n",
      "llama_print_timings:        eval time =    7282.78 ms /    67 runs   (  108.70 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =    9227.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 24%|██▍       | 77/317 [03:19<16:03,  4.02s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.67 ms /    15 runs   (    2.04 ms per token,   489.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.77 ms /    38 tokens (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1471.41 ms /    14 runs   (  105.10 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2285.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 25%|██▍       | 78/317 [03:20<13:20,  3.35s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.96 ms /    11 runs   (    2.00 ms per token,   501.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.91 ms /    35 tokens (   17.68 ms per token,    56.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1048.68 ms /    10 runs   (  104.87 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1789.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 25%|██▍       | 79/317 [03:27<17:01,  4.29s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     104.36 ms /    52 runs   (    2.01 ms per token,   498.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     577.97 ms /    14 tokens (   41.28 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:        eval time =    5324.09 ms /    51 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    6487.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 25%|██▌       | 80/317 [03:29<14:09,  3.58s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.48 ms /    12 runs   (    2.04 ms per token,   490.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.24 ms /    17 tokens (   38.78 ms per token,    25.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.13 ms /    11 runs   (  102.83 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1925.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 26%|██▌       | 81/317 [03:31<12:45,  3.24s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      35.27 ms /    17 runs   (    2.07 ms per token,   482.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.38 ms /    15 tokens (   39.29 ms per token,    25.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1656.16 ms /    16 runs   (  103.51 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2439.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 26%|██▌       | 82/317 [03:35<13:24,  3.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      50.32 ms /    27 runs   (    1.86 ms per token,   536.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.69 ms /    23 tokens (   33.77 ms per token,    29.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2751.08 ms /    26 runs   (  105.81 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    3835.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 26%|██▌       | 83/317 [03:38<12:20,  3.16s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.33 ms /    18 runs   (    2.13 ms per token,   469.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     564.40 ms /    13 tokens (   43.42 ms per token,    23.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1779.14 ms /    17 runs   (  104.66 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2551.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 26%|██▋       | 84/317 [03:40<10:51,  2.80s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.21 ms /    12 runs   (    2.02 ms per token,   495.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.20 ms /    17 tokens (   38.48 ms per token,    25.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.84 ms /    11 runs   (  103.99 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1933.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 27%|██▋       | 85/317 [03:42<10:04,  2.61s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.56 ms /    11 runs   (    1.96 ms per token,   510.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.14 ms /    31 tokens (   31.52 ms per token,    31.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1055.93 ms /    10 runs   (  105.59 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2157.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 27%|██▋       | 86/317 [03:44<09:05,  2.36s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.56 ms /    10 runs   (    2.06 ms per token,   486.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.85 ms /    21 tokens (   35.04 ms per token,    28.54 tokens per second)\n",
      "llama_print_timings:        eval time =     932.95 ms /     9 runs   (  103.66 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1782.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 27%|██▋       | 87/317 [03:46<09:01,  2.35s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.50 ms /    15 runs   (    2.03 ms per token,   491.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.97 ms /    20 tokens (   35.25 ms per token,    28.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.67 ms /    14 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2333.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 28%|██▊       | 88/317 [03:48<08:11,  2.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.33 ms /     9 runs   (    2.04 ms per token,   490.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.91 ms /    48 tokens (   14.77 ms per token,    67.71 tokens per second)\n",
      "llama_print_timings:        eval time =     843.34 ms /     8 runs   (  105.42 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1661.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 28%|██▊       | 89/317 [03:50<08:00,  2.11s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      16.61 ms /     8 runs   (    2.08 ms per token,   481.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.14 ms /    91 tokens (   12.73 ms per token,    78.57 tokens per second)\n",
      "llama_print_timings:        eval time =     750.41 ms /     7 runs   (  107.20 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    2001.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 28%|██▊       | 90/317 [03:52<07:43,  2.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.63 ms /    12 runs   (    1.97 ms per token,   507.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.04 ms /    15 tokens (   40.47 ms per token,    24.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.87 ms /    11 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1880.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 29%|██▊       | 91/317 [03:53<07:18,  1.94s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.77 ms /    10 runs   (    2.08 ms per token,   481.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.27 ms /    39 tokens (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:        eval time =     944.05 ms /     9 runs   (  104.89 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1707.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 29%|██▉       | 92/317 [03:55<07:28,  1.99s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.91 ms /    13 runs   (    2.07 ms per token,   483.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.32 ms /    20 tokens (   35.52 ms per token,    28.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1242.90 ms /    12 runs   (  103.57 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2101.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 29%|██▉       | 93/317 [03:58<07:41,  2.06s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.38 ms /    14 runs   (    2.10 ms per token,   476.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.01 ms /    44 tokens (   15.50 ms per token,    64.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1376.38 ms /    13 runs   (  105.88 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    2222.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 30%|██▉       | 94/317 [04:00<07:54,  2.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.99 ms /    15 runs   (    2.07 ms per token,   483.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.88 ms /    17 tokens (   38.05 ms per token,    26.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1450.46 ms /    14 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2268.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 30%|██▉       | 95/317 [04:02<08:08,  2.20s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.89 ms /    13 runs   (    2.07 ms per token,   483.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     953.50 ms /    31 tokens (   30.76 ms per token,    32.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1260.90 ms /    12 runs   (  105.08 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    2362.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 30%|███       | 96/317 [04:04<07:50,  2.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.91 ms /    10 runs   (    2.09 ms per token,   478.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     883.62 ms /    28 tokens (   31.56 ms per token,    31.69 tokens per second)\n",
      "llama_print_timings:        eval time =     955.84 ms /     9 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    1956.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 31%|███       | 97/317 [04:07<08:48,  2.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.77 ms /    20 runs   (    2.14 ms per token,   467.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.59 ms /    22 tokens (   35.48 ms per token,    28.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2017.49 ms /    19 runs   (  106.18 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    3041.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 31%|███       | 98/317 [04:09<08:07,  2.23s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.69 ms /    11 runs   (    2.06 ms per token,   484.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.79 ms /    16 tokens (   39.99 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1043.13 ms /    10 runs   (  104.31 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1811.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 31%|███       | 99/317 [04:17<14:16,  3.93s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     122.04 ms /    62 runs   (    1.97 ms per token,   508.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.58 ms /    47 tokens (   14.93 ms per token,    66.99 tokens per second)\n",
      "llama_print_timings:        eval time =    6494.27 ms /    61 runs   (  106.46 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    7900.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 32%|███▏      | 100/317 [04:19<12:25,  3.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.29 ms /    13 runs   (    2.10 ms per token,   476.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     876.94 ms /    27 tokens (   32.48 ms per token,    30.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1255.65 ms /    12 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2280.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 32%|███▏      | 101/317 [04:21<10:37,  2.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.82 ms /    10 runs   (    2.08 ms per token,   480.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.71 ms /    54 tokens (   13.90 ms per token,    71.93 tokens per second)\n",
      "llama_print_timings:        eval time =     947.11 ms /     9 runs   (  105.23 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    1812.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 32%|███▏      | 102/317 [04:24<10:45,  3.00s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.07 ms /    10 runs   (    1.91 ms per token,   524.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2000.87 ms /   176 tokens (   11.37 ms per token,    87.96 tokens per second)\n",
      "llama_print_timings:        eval time =     992.93 ms /     9 runs   (  110.33 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    3108.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 32%|███▏      | 103/317 [04:26<09:28,  2.66s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.27 ms /    10 runs   (    2.13 ms per token,   470.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.69 ms /    24 tokens (   32.99 ms per token,    30.31 tokens per second)\n",
      "llama_print_timings:        eval time =     940.42 ms /     9 runs   (  104.49 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1847.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 33%|███▎      | 104/317 [04:28<08:28,  2.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.31 ms /    11 runs   (    2.03 ms per token,   493.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     579.87 ms /    14 tokens (   41.42 ms per token,    24.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1042.01 ms /    10 runs   (  104.20 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1752.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 33%|███▎      | 105/317 [04:31<09:00,  2.55s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.99 ms /    21 runs   (    2.09 ms per token,   477.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.20 ms /    15 tokens (   40.28 ms per token,    24.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2081.84 ms /    20 runs   (  104.09 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    2927.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 33%|███▎      | 106/317 [04:32<08:08,  2.31s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.38 ms /    10 runs   (    2.04 ms per token,   490.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.03 ms /    20 tokens (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_print_timings:        eval time =     934.97 ms /     9 runs   (  103.89 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1757.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 34%|███▍      | 107/317 [04:38<11:15,  3.22s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      82.08 ms /    40 runs   (    2.05 ms per token,   487.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.91 ms /    21 tokens (   34.85 ms per token,    28.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4113.49 ms /    39 runs   (  105.47 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    5317.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 34%|███▍      | 108/317 [04:40<09:50,  2.83s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.22 ms /    11 runs   (    2.02 ms per token,   495.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.99 ms /    49 tokens (   15.02 ms per token,    66.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.72 ms /    10 runs   (  104.97 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1912.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 34%|███▍      | 109/317 [04:42<09:19,  2.69s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.33 ms /    16 runs   (    2.08 ms per token,   480.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.82 ms /    16 tokens (   38.99 ms per token,    25.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1558.94 ms /    15 runs   (  103.93 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    2366.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 35%|███▍      | 110/317 [04:44<08:25,  2.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.45 ms /    11 runs   (    2.04 ms per token,   490.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.00 ms /    20 tokens (   35.05 ms per token,    28.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1031.43 ms /    10 runs   (  103.14 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    1859.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 35%|███▌      | 111/317 [04:46<07:44,  2.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.30 ms /    10 runs   (    2.03 ms per token,   492.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.22 ms /    54 tokens (   13.89 ms per token,    71.98 tokens per second)\n",
      "llama_print_timings:        eval time =     949.16 ms /     9 runs   (  105.46 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    1813.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 35%|███▌      | 112/317 [04:48<07:18,  2.14s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.50 ms /    10 runs   (    1.85 ms per token,   540.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.67 ms /    60 tokens (   13.21 ms per token,    75.69 tokens per second)\n",
      "llama_print_timings:        eval time =     957.98 ms /     9 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    1864.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 36%|███▌      | 113/317 [04:49<06:59,  2.05s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.54 ms /    11 runs   (    2.05 ms per token,   488.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.55 ms /    44 tokens (   15.40 ms per token,    64.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.50 ms /    10 runs   (  104.55 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    1848.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 36%|███▌      | 114/317 [04:51<06:47,  2.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.84 ms /    11 runs   (    1.99 ms per token,   503.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.13 ms /    20 tokens (   36.56 ms per token,    27.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1036.35 ms /    10 runs   (  103.64 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1892.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 36%|███▋      | 115/317 [04:53<06:36,  1.96s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.00 ms /    11 runs   (    1.91 ms per token,   523.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.43 ms /    42 tokens (   16.01 ms per token,    62.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1054.73 ms /    10 runs   (  105.47 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    1852.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 37%|███▋      | 116/317 [04:56<07:03,  2.11s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.00 ms /    14 runs   (    2.00 ms per token,   499.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.27 ms /    30 tokens (   30.71 ms per token,    32.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1362.57 ms /    13 runs   (  104.81 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    2442.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 37%|███▋      | 117/317 [04:58<07:11,  2.16s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.50 ms /    15 runs   (    2.10 ms per token,   476.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.81 ms /    33 tokens (   18.51 ms per token,    54.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1478.96 ms /    14 runs   (  105.64 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2270.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 37%|███▋      | 118/317 [05:00<06:59,  2.11s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.21 ms /    11 runs   (    1.93 ms per token,   518.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.14 ms /    62 tokens (   12.94 ms per token,    77.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1060.07 ms /    10 runs   (  106.01 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    1985.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 38%|███▊      | 119/317 [05:03<07:53,  2.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.93 ms /    21 runs   (    2.04 ms per token,   489.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.62 ms /    21 tokens (   34.41 ms per token,    29.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2085.14 ms /    20 runs   (  104.26 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    3049.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 38%|███▊      | 120/317 [05:05<07:30,  2.29s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.25 ms /    10 runs   (    2.02 ms per token,   493.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     968.02 ms /    65 tokens (   14.89 ms per token,    67.15 tokens per second)\n",
      "llama_print_timings:        eval time =     954.06 ms /     9 runs   (  106.01 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    2040.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 38%|███▊      | 121/317 [05:07<07:30,  2.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.20 ms /    12 runs   (    2.02 ms per token,   495.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.43 ms /    71 tokens (   14.19 ms per token,    70.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.30 ms /    11 runs   (  106.03 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    2318.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 38%|███▊      | 122/317 [05:10<07:18,  2.25s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.04 ms /    13 runs   (    2.08 ms per token,   480.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.11 ms /    44 tokens (   15.73 ms per token,    63.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1284.06 ms /    12 runs   (  107.00 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    2127.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 39%|███▉      | 123/317 [05:12<07:17,  2.25s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.84 ms /    11 runs   (    2.08 ms per token,   481.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1061.24 ms /    78 tokens (   13.61 ms per token,    73.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1067.26 ms /    10 runs   (  106.73 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    2255.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 39%|███▉      | 124/317 [05:14<07:06,  2.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.51 ms /    13 runs   (    2.04 ms per token,   490.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.41 ms /    20 tokens (   35.12 ms per token,    28.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1245.41 ms /    12 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2095.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 39%|███▉      | 125/317 [05:16<07:00,  2.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.37 ms /    14 runs   (    1.96 ms per token,   511.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     622.15 ms /    35 tokens (   17.78 ms per token,    56.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1367.30 ms /    13 runs   (  105.18 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2149.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 40%|███▉      | 126/317 [05:18<06:51,  2.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.54 ms /    11 runs   (    2.05 ms per token,   488.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     867.09 ms /    27 tokens (   32.11 ms per token,    31.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1056.33 ms /    10 runs   (  105.63 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2053.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 40%|████      | 127/317 [05:20<06:50,  2.16s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.25 ms /    10 runs   (    1.72 ms per token,   579.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.24 ms /    85 tokens (   13.04 ms per token,    76.70 tokens per second)\n",
      "llama_print_timings:        eval time =     959.09 ms /     9 runs   (  106.57 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    2179.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 40%|████      | 128/317 [05:22<06:19,  2.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.27 ms /    10 runs   (    2.03 ms per token,   493.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.96 ms /    15 tokens (   39.40 ms per token,    25.38 tokens per second)\n",
      "llama_print_timings:        eval time =     932.48 ms /     9 runs   (  103.61 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1637.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 41%|████      | 129/317 [05:24<06:07,  1.96s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.19 ms /    11 runs   (    2.02 ms per token,   495.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.21 ms /    18 tokens (   37.23 ms per token,    26.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1037.78 ms /    10 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1833.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 41%|████      | 130/317 [05:26<06:32,  2.10s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.16 ms /    10 runs   (    2.02 ms per token,   496.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.98 ms /   112 tokens (   11.76 ms per token,    85.04 tokens per second)\n",
      "llama_print_timings:        eval time =     993.28 ms /     9 runs   (  110.36 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    2429.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 41%|████▏     | 131/317 [05:29<07:25,  2.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      44.77 ms /    22 runs   (    2.03 ms per token,   491.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.31 ms /    16 tokens (   40.64 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2184.66 ms /    21 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    3085.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 42%|████▏     | 132/317 [05:31<07:06,  2.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.04 ms /    10 runs   (    1.80 ms per token,   554.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.05 ms /    71 tokens (   14.18 ms per token,    70.50 tokens per second)\n",
      "llama_print_timings:        eval time =     962.35 ms /     9 runs   (  106.93 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    2082.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 42%|████▏     | 133/317 [05:34<07:33,  2.47s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.22 ms /    10 runs   (    1.72 ms per token,   580.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1747.69 ms /   146 tokens (   11.97 ms per token,    83.54 tokens per second)\n",
      "llama_print_timings:        eval time =     981.17 ms /     9 runs   (  109.02 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    2840.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 42%|████▏     | 134/317 [05:42<12:02,  3.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     110.46 ms /    56 runs   (    1.97 ms per token,   506.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.18 ms /    62 tokens (   13.10 ms per token,    76.34 tokens per second)\n",
      "llama_print_timings:        eval time =    5930.83 ms /    55 runs   (  107.83 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    7394.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 43%|████▎     | 135/317 [05:46<12:21,  4.08s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      68.46 ms /    33 runs   (    2.07 ms per token,   482.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     627.54 ms /    36 tokens (   17.43 ms per token,    57.37 tokens per second)\n",
      "llama_print_timings:        eval time =    3361.46 ms /    32 runs   (  105.05 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    4369.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 43%|████▎     | 136/317 [05:48<10:40,  3.54s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.17 ms /    15 runs   (    2.01 ms per token,   497.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.51 ms /    17 tokens (   38.27 ms per token,    26.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1451.96 ms /    14 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2276.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 43%|████▎     | 137/317 [05:50<09:19,  3.11s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.39 ms /    10 runs   (    1.84 ms per token,   543.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.29 ms /    75 tokens (   13.82 ms per token,    72.37 tokens per second)\n",
      "llama_print_timings:        eval time =     958.93 ms /     9 runs   (  106.55 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    2108.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▎     | 138/317 [05:53<08:43,  2.92s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.27 ms /    11 runs   (    1.84 ms per token,   542.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1287.61 ms /   110 tokens (   11.71 ms per token,    85.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1072.01 ms /    10 runs   (  107.20 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    2482.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▍     | 139/317 [05:55<08:06,  2.73s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.91 ms /    15 runs   (    2.06 ms per token,   485.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.53 ms /    40 tokens (   16.26 ms per token,    61.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1463.22 ms /    14 runs   (  104.52 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    2286.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▍     | 140/317 [05:57<07:38,  2.59s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      25.49 ms /    13 runs   (    1.96 ms per token,   509.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.46 ms /    26 tokens (   32.29 ms per token,    30.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1252.38 ms /    12 runs   (  104.37 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    2245.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▍     | 141/317 [06:00<07:12,  2.46s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.86 ms /    11 runs   (    1.80 ms per token,   554.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     973.58 ms /    68 tokens (   14.32 ms per token,    69.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1053.88 ms /    10 runs   (  105.39 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    2149.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 45%|████▍     | 142/317 [06:02<06:56,  2.38s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.80 ms /    10 runs   (    1.98 ms per token,   505.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1116.70 ms /    88 tokens (   12.69 ms per token,    78.80 tokens per second)\n",
      "llama_print_timings:        eval time =     954.31 ms /     9 runs   (  106.03 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    2184.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 45%|████▌     | 143/317 [06:04<06:45,  2.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.30 ms /    11 runs   (    2.03 ms per token,   493.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.21 ms /    76 tokens (   13.59 ms per token,    73.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1053.01 ms /    10 runs   (  105.30 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2211.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 45%|████▌     | 144/317 [06:06<06:26,  2.24s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.91 ms /    11 runs   (    2.08 ms per token,   480.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.12 ms /    64 tokens (   12.94 ms per token,    77.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1060.23 ms /    10 runs   (  106.02 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    2014.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 46%|████▌     | 145/317 [06:08<06:06,  2.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.00 ms /    10 runs   (    2.10 ms per token,   476.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.41 ms /    26 tokens (   31.75 ms per token,    31.50 tokens per second)\n",
      "llama_print_timings:        eval time =     943.77 ms /     9 runs   (  104.86 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1884.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 46%|████▌     | 146/317 [06:10<06:18,  2.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.38 ms /    10 runs   (    1.94 ms per token,   516.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.68 ms /   114 tokens (   11.65 ms per token,    85.86 tokens per second)\n",
      "llama_print_timings:        eval time =     960.03 ms /     9 runs   (  106.67 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    2399.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 46%|████▋     | 147/317 [06:11<05:03,  1.78s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /     2 runs   (    1.84 ms per token,   543.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.92 ms /    39 tokens (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:        eval time =     105.81 ms /     1 runs   (  105.81 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =     772.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 47%|████▋     | 148/317 [06:13<05:15,  1.86s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.91 ms /    13 runs   (    2.07 ms per token,   483.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.90 ms /    36 tokens (   17.25 ms per token,    57.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1270.80 ms /    12 runs   (  105.90 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    2047.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 47%|████▋     | 149/317 [06:15<05:37,  2.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      32.52 ms /    16 runs   (    2.03 ms per token,   491.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.74 ms /    16 tokens (   37.86 ms per token,    26.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1544.83 ms /    15 runs   (  102.99 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    2331.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 47%|████▋     | 150/317 [06:18<05:41,  2.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.02 ms /    11 runs   (    2.00 ms per token,   499.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     952.25 ms /    31 tokens (   30.72 ms per token,    32.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1047.60 ms /    10 runs   (  104.76 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2126.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 48%|████▊     | 151/317 [06:20<05:49,  2.10s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.05 ms /    14 runs   (    2.08 ms per token,   481.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.34 ms /    52 tokens (   13.85 ms per token,    72.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1355.24 ms /    13 runs   (  104.25 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    2234.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 48%|████▊     | 152/317 [06:22<05:31,  2.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.46 ms /    10 runs   (    2.05 ms per token,   488.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.02 ms /    22 tokens (   33.41 ms per token,    29.93 tokens per second)\n",
      "llama_print_timings:        eval time =     929.23 ms /     9 runs   (  103.25 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1778.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 48%|████▊     | 153/317 [06:24<06:01,  2.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.32 ms /    15 runs   (    1.95 ms per token,   511.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1017.81 ms /    74 tokens (   13.75 ms per token,    72.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1479.90 ms /    14 runs   (  105.71 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    2666.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 49%|████▊     | 154/317 [06:27<06:10,  2.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.34 ms /    15 runs   (    2.09 ms per token,   478.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     805.02 ms /    25 tokens (   32.20 ms per token,    31.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1452.00 ms /    14 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2427.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 49%|████▉     | 155/317 [06:29<06:17,  2.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.12 ms /    12 runs   (    2.01 ms per token,   497.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.50 ms /    94 tokens (   12.29 ms per token,    81.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.40 ms /    11 runs   (  106.22 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    2459.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 49%|████▉     | 156/317 [06:31<06:13,  2.32s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.02 ms /    11 runs   (    1.91 ms per token,   523.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.96 ms /    88 tokens (   12.57 ms per token,    79.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1060.93 ms /    10 runs   (  106.09 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    2290.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|████▉     | 157/317 [06:34<06:13,  2.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.41 ms /    15 runs   (    2.09 ms per token,   477.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     734.62 ms /    22 tokens (   33.39 ms per token,    29.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1443.86 ms /    14 runs   (  103.13 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    2348.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|████▉     | 158/317 [06:37<06:46,  2.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      41.90 ms /    22 runs   (    1.90 ms per token,   525.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.74 ms /    18 tokens (   36.32 ms per token,    27.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2176.27 ms /    21 runs   (  103.63 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    3078.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|█████     | 159/317 [06:39<06:31,  2.48s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.89 ms /    12 runs   (    2.07 ms per token,   482.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.41 ms /    31 tokens (   32.14 ms per token,    31.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.12 ms /    11 runs   (  105.56 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2297.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|█████     | 160/317 [06:51<13:40,  5.23s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     168.93 ms /    82 runs   (    2.06 ms per token,   485.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1695.89 ms /   141 tokens (   12.03 ms per token,    83.14 tokens per second)\n",
      "llama_print_timings:        eval time =    8965.51 ms /    81 runs   (  110.69 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =   11625.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 51%|█████     | 161/317 [06:53<11:01,  4.24s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.41 ms /    10 runs   (    2.04 ms per token,   490.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     881.15 ms /    28 tokens (   31.47 ms per token,    31.78 tokens per second)\n",
      "llama_print_timings:        eval time =     938.69 ms /     9 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1933.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 51%|█████     | 162/317 [07:01<14:18,  5.54s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      40.62 ms /    20 runs   (    2.03 ms per token,   492.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5993.54 ms /   499 tokens (   12.01 ms per token,    83.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2330.79 ms /    19 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =    8555.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 51%|█████▏    | 163/317 [07:06<13:47,  5.37s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      70.09 ms /    35 runs   (    2.00 ms per token,   499.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     985.12 ms /    70 tokens (   14.07 ms per token,    71.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3596.01 ms /    34 runs   (  105.76 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    4977.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 52%|█████▏    | 164/317 [07:08<11:06,  4.36s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.25 ms /    10 runs   (    2.13 ms per token,   470.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     909.12 ms /    30 tokens (   30.30 ms per token,    33.00 tokens per second)\n",
      "llama_print_timings:        eval time =     949.38 ms /     9 runs   (  105.49 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    1979.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 52%|█████▏    | 165/317 [07:11<10:03,  3.97s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.68 ms /    22 runs   (    1.99 ms per token,   503.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.29 ms /    35 tokens (   17.61 ms per token,    56.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2199.28 ms /    21 runs   (  104.73 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    3067.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 52%|█████▏    | 166/317 [07:13<08:18,  3.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.35 ms /    10 runs   (    1.94 ms per token,   516.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.06 ms /    46 tokens (   14.87 ms per token,    67.25 tokens per second)\n",
      "llama_print_timings:        eval time =     934.53 ms /     9 runs   (  103.84 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1730.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 53%|█████▎    | 167/317 [07:16<08:03,  3.22s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      41.33 ms /    21 runs   (    1.97 ms per token,   508.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.16 ms /    48 tokens (   14.50 ms per token,    68.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2104.69 ms /    20 runs   (  105.23 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    3040.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 53%|█████▎    | 168/317 [07:21<09:09,  3.69s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      79.98 ms /    41 runs   (    1.95 ms per token,   512.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    4298.40 ms /    41 runs   (  104.84 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    4765.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 53%|█████▎    | 169/317 [07:23<07:51,  3.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.55 ms /    11 runs   (    2.05 ms per token,   487.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.37 ms /    27 tokens (   31.53 ms per token,    31.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1033.02 ms /    10 runs   (  103.30 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    2009.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 54%|█████▎    | 170/317 [07:28<09:19,  3.80s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      71.88 ms /    37 runs   (    1.94 ms per token,   514.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     999.50 ms /    72 tokens (   13.88 ms per token,    72.04 tokens per second)\n",
      "llama_print_timings:        eval time =    3823.85 ms /    36 runs   (  106.22 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    5241.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 54%|█████▍    | 171/317 [07:30<08:06,  3.34s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.21 ms /    11 runs   (    1.93 ms per token,   518.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1056.60 ms /    80 tokens (   13.21 ms per token,    75.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1055.16 ms /    10 runs   (  105.52 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    2235.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 54%|█████▍    | 172/317 [07:32<07:05,  2.93s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.59 ms /    11 runs   (    1.96 ms per token,   509.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     829.97 ms /    26 tokens (   31.92 ms per token,    31.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1036.85 ms /    10 runs   (  103.68 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1991.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 55%|█████▍    | 173/317 [07:41<10:50,  4.52s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     110.64 ms /    54 runs   (    2.05 ms per token,   488.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1758.13 ms /   152 tokens (   11.57 ms per token,    86.46 tokens per second)\n",
      "llama_print_timings:        eval time =    5828.05 ms /    53 runs   (  109.96 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    8206.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 55%|█████▍    | 174/317 [07:43<09:07,  3.83s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.14 ms /    11 runs   (    2.01 ms per token,   496.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.18 ms /    77 tokens (   13.38 ms per token,    74.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1051.08 ms /    10 runs   (  105.11 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2206.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 55%|█████▌    | 175/317 [07:45<08:04,  3.41s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      25.39 ms /    13 runs   (    1.95 ms per token,   512.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.29 ms /    77 tokens (   13.32 ms per token,    75.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1260.88 ms /    12 runs   (  105.07 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    2431.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▌    | 176/317 [07:53<10:48,  4.60s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     111.80 ms /    55 runs   (    2.03 ms per token,   491.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.81 ms /    66 tokens (   14.54 ms per token,    68.76 tokens per second)\n",
      "llama_print_timings:        eval time =    5761.14 ms /    54 runs   (  106.69 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    7366.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▌    | 177/317 [07:56<09:37,  4.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.52 ms /    16 runs   (    1.97 ms per token,   507.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1239.28 ms /   105 tokens (   11.80 ms per token,    84.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1602.37 ms /    15 runs   (  106.82 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    3023.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▌    | 178/317 [07:58<08:05,  3.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.68 ms /    11 runs   (    1.97 ms per token,   507.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     801.05 ms /    62 tokens (   12.92 ms per token,    77.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1069.05 ms /    10 runs   (  106.90 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    2001.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▋    | 179/317 [08:09<13:08,  5.71s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     157.83 ms /    77 runs   (    2.05 ms per token,   487.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.12 ms /   139 tokens (   12.03 ms per token,    83.13 tokens per second)\n",
      "llama_print_timings:        eval time =    8339.58 ms /    76 runs   (  109.73 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =   10895.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 57%|█████▋    | 180/317 [08:10<10:02,  4.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.41 ms /    11 runs   (    2.13 ms per token,   469.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    1192.27 ms /    11 runs   (  108.39 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    1319.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 57%|█████▋    | 181/317 [08:18<12:27,  5.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     133.07 ms /    65 runs   (    2.05 ms per token,   488.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.75 ms /    33 tokens (   18.20 ms per token,    54.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6703.37 ms /    64 runs   (  104.74 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    8045.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 57%|█████▋    | 182/317 [08:22<11:16,  5.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.82 ms /    13 runs   (    2.06 ms per token,   484.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2369.42 ms /   222 tokens (   10.67 ms per token,    93.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1347.19 ms /    12 runs   (  112.27 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    3867.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 58%|█████▊    | 183/317 [08:24<09:09,  4.10s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.03 ms /    11 runs   (    2.00 ms per token,   499.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.64 ms /    61 tokens (   12.99 ms per token,    76.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.81 ms /    10 runs   (  104.98 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1966.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 58%|█████▊    | 184/317 [08:30<10:33,  4.77s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      95.54 ms /    50 runs   (    1.91 ms per token,   523.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.70 ms /    18 tokens (   36.59 ms per token,    27.33 tokens per second)\n",
      "llama_print_timings:        eval time =    5094.54 ms /    49 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    6322.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 58%|█████▊    | 185/317 [08:34<09:46,  4.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.38 ms /    11 runs   (    1.85 ms per token,   539.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2425.71 ms /   226 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.71 ms /    10 runs   (  112.37 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    3673.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 59%|█████▊    | 186/317 [08:51<17:41,  8.10s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     190.91 ms /   128 runs   (    1.49 ms per token,   670.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1272.08 ms /   108 tokens (   11.78 ms per token,    84.90 tokens per second)\n",
      "llama_print_timings:        eval time =   13955.18 ms /   127 runs   (  109.88 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =   16632.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 59%|█████▉    | 187/317 [08:52<13:27,  6.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.57 ms /    10 runs   (    2.06 ms per token,   486.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.43 ms /    20 tokens (   36.82 ms per token,    27.16 tokens per second)\n",
      "llama_print_timings:        eval time =     935.07 ms /     9 runs   (  103.90 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1792.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 59%|█████▉    | 188/317 [08:54<10:36,  4.94s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.71 ms /    11 runs   (    1.88 ms per token,   531.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     781.75 ms /    60 tokens (   13.03 ms per token,    76.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1058.20 ms /    10 runs   (  105.82 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    1963.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 60%|█████▉    | 189/317 [08:56<08:26,  3.96s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.84 ms /    10 runs   (    1.98 ms per token,   504.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.65 ms /    34 tokens (   17.90 ms per token,    55.86 tokens per second)\n",
      "llama_print_timings:        eval time =     939.26 ms /     9 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1660.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 60%|█████▉    | 190/317 [08:59<07:35,  3.59s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.61 ms /    10 runs   (    1.76 ms per token,   567.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.94 ms /   133 tokens (   12.30 ms per token,    81.30 tokens per second)\n",
      "llama_print_timings:        eval time =     974.39 ms /     9 runs   (  108.27 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =    2721.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 60%|██████    | 191/317 [09:01<06:56,  3.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.48 ms /    14 runs   (    2.03 ms per token,   491.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1098.02 ms /    87 tokens (   12.62 ms per token,    79.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1378.90 ms /    13 runs   (  106.07 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    2636.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 61%|██████    | 192/317 [09:03<05:51,  2.82s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.62 ms /    11 runs   (    1.97 ms per token,   508.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     519.81 ms /    12 tokens (   43.32 ms per token,    23.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1026.95 ms /    10 runs   (  102.69 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1671.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 61%|██████    | 193/317 [09:05<05:37,  2.72s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.71 ms /    17 runs   (    1.98 ms per token,   504.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     626.77 ms /    37 tokens (   16.94 ms per token,    59.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1673.25 ms /    16 runs   (  104.58 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2493.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 61%|██████    | 194/317 [09:09<05:54,  2.88s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      47.16 ms /    23 runs   (    2.05 ms per token,   487.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.84 ms /    20 tokens (   35.09 ms per token,    28.50 tokens per second)\n",
      "llama_print_timings:        eval time =    2277.74 ms /    22 runs   (  103.53 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    3245.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 62%|██████▏   | 195/317 [09:12<05:57,  2.93s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.93 ms /    22 runs   (    2.00 ms per token,   500.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.93 ms /    16 tokens (   38.81 ms per token,    25.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2161.32 ms /    21 runs   (  102.92 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3031.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 62%|██████▏   | 196/317 [09:13<05:08,  2.55s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.23 ms /    10 runs   (    2.02 ms per token,   494.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     622.26 ms /    36 tokens (   17.28 ms per token,    57.85 tokens per second)\n",
      "llama_print_timings:        eval time =     931.68 ms /     9 runs   (  103.52 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1667.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 62%|██████▏   | 197/317 [09:15<04:44,  2.37s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.79 ms /     9 runs   (    1.98 ms per token,   505.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1001.49 ms /    70 tokens (   14.31 ms per token,    69.90 tokens per second)\n",
      "llama_print_timings:        eval time =     839.10 ms /     8 runs   (  104.89 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1941.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 62%|██████▏   | 198/317 [09:29<11:19,  5.71s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     150.58 ms /    83 runs   (    1.81 ms per token,   551.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3111.42 ms /   278 tokens (   11.19 ms per token,    89.35 tokens per second)\n",
      "llama_print_timings:        eval time =    9431.43 ms /    82 runs   (  115.02 ms per token,     8.69 tokens per second)\n",
      "llama_print_timings:       total time =   13492.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 63%|██████▎   | 199/317 [09:31<08:59,  4.57s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.80 ms /    10 runs   (    2.08 ms per token,   480.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     868.74 ms /    26 tokens (   33.41 ms per token,    29.93 tokens per second)\n",
      "llama_print_timings:        eval time =     932.99 ms /     9 runs   (  103.67 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1915.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 63%|██████▎   | 200/317 [09:34<08:11,  4.20s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      47.38 ms /    24 runs   (    1.97 ms per token,   506.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.15 ms /    43 tokens (   15.52 ms per token,    64.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2390.96 ms /    23 runs   (  103.95 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    3329.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 63%|██████▎   | 201/317 [09:36<06:56,  3.59s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.56 ms /    14 runs   (    2.04 ms per token,   490.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.53 ms /    40 tokens (   16.29 ms per token,    61.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1351.66 ms /    13 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    2162.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 64%|██████▎   | 202/317 [09:39<06:08,  3.20s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.54 ms /    15 runs   (    2.10 ms per token,   475.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.53 ms /    41 tokens (   15.96 ms per token,    62.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1468.30 ms /    14 runs   (  104.88 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    2295.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 64%|██████▍   | 203/317 [09:42<06:06,  3.22s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.07 ms /    11 runs   (    2.01 ms per token,   498.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2020.48 ms /   182 tokens (   11.10 ms per token,    90.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.79 ms /    10 runs   (  109.98 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    3245.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 64%|██████▍   | 204/317 [09:45<06:12,  3.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      50.90 ms /    25 runs   (    2.04 ms per token,   491.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.65 ms /    22 tokens (   33.21 ms per token,    30.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2474.86 ms /    24 runs   (  103.12 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    3487.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 65%|██████▍   | 205/317 [09:47<05:20,  2.86s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.62 ms /    10 runs   (    2.06 ms per token,   484.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     758.59 ms /    57 tokens (   13.31 ms per token,    75.14 tokens per second)\n",
      "llama_print_timings:        eval time =     943.10 ms /     9 runs   (  104.79 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1818.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 65%|██████▍   | 206/317 [09:50<05:00,  2.71s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.45 ms /    17 runs   (    2.03 ms per token,   493.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     529.16 ms /    12 tokens (   44.10 ms per token,    22.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1641.00 ms /    16 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    2362.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 65%|██████▌   | 207/317 [09:52<04:48,  2.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.36 ms /    11 runs   (    1.85 ms per token,   540.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.83 ms /   102 tokens (   12.09 ms per token,    82.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1066.90 ms /    10 runs   (  106.69 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    2422.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 66%|██████▌   | 208/317 [09:55<04:53,  2.69s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      41.48 ms /    20 runs   (    2.07 ms per token,   482.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.27 ms /    36 tokens (   17.23 ms per token,    58.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1988.98 ms /    19 runs   (  104.68 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2845.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 66%|██████▌   | 209/317 [09:57<04:48,  2.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.62 ms /    15 runs   (    1.97 ms per token,   506.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     983.65 ms /    31 tokens (   31.73 ms per token,    31.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1465.71 ms /    14 runs   (  104.69 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2621.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 66%|██████▌   | 210/317 [10:00<04:26,  2.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.23 ms /     9 runs   (    2.03 ms per token,   493.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1102.85 ms /    89 tokens (   12.39 ms per token,    80.70 tokens per second)\n",
      "llama_print_timings:        eval time =     846.88 ms /     8 runs   (  105.86 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    2051.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 67%|██████▋   | 211/317 [10:02<04:38,  2.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      40.29 ms /    20 runs   (    2.01 ms per token,   496.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.47 ms /    22 tokens (   33.57 ms per token,    29.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1970.88 ms /    19 runs   (  103.73 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2937.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 67%|██████▋   | 212/317 [10:04<04:09,  2.38s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.28 ms /    11 runs   (    2.03 ms per token,   493.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.28 ms /    34 tokens (   17.89 ms per token,    55.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.78 ms /    10 runs   (  104.98 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1786.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 67%|██████▋   | 213/317 [10:07<04:04,  2.36s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.01 ms /    11 runs   (    2.00 ms per token,   499.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1107.87 ms /    88 tokens (   12.59 ms per token,    79.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1068.08 ms /    10 runs   (  106.81 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    2302.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.74 ms /    10 runs   (    1.97 ms per token,   506.69 tokens per second)\n",
      " 68%|██████▊   | 214/317 [10:08<03:47,  2.21s/it]llama_print_timings: prompt eval time =     780.53 ms /    60 tokens (   13.01 ms per token,    76.87 tokens per second)\n",
      "llama_print_timings:        eval time =     952.99 ms /     9 runs   (  105.89 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1848.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 68%|██████▊   | 215/317 [10:13<05:08,  3.02s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      77.84 ms /    39 runs   (    2.00 ms per token,   501.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     567.01 ms /    14 tokens (   40.50 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3923.20 ms /    38 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    4929.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 68%|██████▊   | 216/317 [10:21<07:14,  4.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     118.30 ms /    59 runs   (    2.01 ms per token,   498.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     583.54 ms /    15 tokens (   38.90 ms per token,    25.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6021.19 ms /    58 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    7277.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 68%|██████▊   | 217/317 [10:24<06:29,  3.89s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.76 ms /    21 runs   (    2.04 ms per token,   491.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.02 ms /    17 tokens (   37.18 ms per token,    26.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2059.13 ms /    20 runs   (  102.96 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    2931.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 69%|██████▉   | 218/317 [10:25<05:25,  3.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.43 ms /    10 runs   (    2.04 ms per token,   489.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     801.98 ms /    63 tokens (   12.73 ms per token,    78.56 tokens per second)\n",
      "llama_print_timings:        eval time =     946.98 ms /     9 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    1862.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 69%|██████▉   | 219/317 [10:27<04:35,  2.81s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.73 ms /    10 runs   (    2.17 ms per token,   460.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.38 ms /    38 tokens (   16.69 ms per token,    59.90 tokens per second)\n",
      "llama_print_timings:        eval time =     948.43 ms /     9 runs   (  105.38 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1705.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 69%|██████▉   | 220/317 [10:29<04:05,  2.53s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.12 ms /    12 runs   (    2.01 ms per token,   497.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.73 ms /    14 tokens (   42.55 ms per token,    23.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.24 ms /    11 runs   (  102.57 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1860.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 70%|██████▉   | 221/317 [10:33<04:44,  2.96s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      56.82 ms /    28 runs   (    2.03 ms per token,   492.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     844.49 ms /    27 tokens (   31.28 ms per token,    31.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2798.57 ms /    27 runs   (  103.65 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    3961.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 70%|███████   | 222/317 [10:35<04:25,  2.80s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      25.84 ms /    13 runs   (    1.99 ms per token,   503.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1007.77 ms /    74 tokens (   13.62 ms per token,    73.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.73 ms /    12 runs   (  105.31 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2419.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 70%|███████   | 223/317 [10:38<04:03,  2.59s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.15 ms /     9 runs   (    2.02 ms per token,   495.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.01 ms /    94 tokens (   12.19 ms per token,    82.02 tokens per second)\n",
      "llama_print_timings:        eval time =     860.75 ms /     8 runs   (  107.59 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    2111.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 71%|███████   | 224/317 [10:39<03:36,  2.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.32 ms /     9 runs   (    2.04 ms per token,   491.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.20 ms /    57 tokens (   13.42 ms per token,    74.49 tokens per second)\n",
      "llama_print_timings:        eval time =     831.26 ms /     8 runs   (  103.91 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1700.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 71%|███████   | 225/317 [10:43<04:04,  2.66s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      50.65 ms /    25 runs   (    2.03 ms per token,   493.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.73 ms /    40 tokens (   16.17 ms per token,    61.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2499.10 ms /    24 runs   (  104.13 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    3430.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 71%|███████▏  | 226/317 [10:50<06:07,  4.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     108.89 ms /    53 runs   (    2.05 ms per token,   486.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1100.23 ms /    88 tokens (   12.50 ms per token,    79.98 tokens per second)\n",
      "llama_print_timings:        eval time =    5553.53 ms /    52 runs   (  106.80 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    7260.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 72%|███████▏  | 227/317 [10:55<06:22,  4.25s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      65.31 ms /    32 runs   (    2.04 ms per token,   490.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.37 ms /    80 tokens (   13.43 ms per token,    74.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3295.66 ms /    31 runs   (  106.31 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    4738.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 72%|███████▏  | 228/317 [10:57<05:15,  3.55s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.73 ms /    10 runs   (    1.97 ms per token,   506.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.62 ms /    27 tokens (   31.54 ms per token,    31.70 tokens per second)\n",
      "llama_print_timings:        eval time =     936.74 ms /     9 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1902.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 72%|███████▏  | 229/317 [10:58<04:27,  3.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.76 ms /    10 runs   (    2.08 ms per token,   481.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     777.59 ms /    24 tokens (   32.40 ms per token,    30.86 tokens per second)\n",
      "llama_print_timings:        eval time =     935.71 ms /     9 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1841.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 73%|███████▎  | 230/317 [11:00<03:52,  2.68s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.37 ms /    12 runs   (    2.03 ms per token,   492.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     554.99 ms /    13 tokens (   42.69 ms per token,    23.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.22 ms /    11 runs   (  103.29 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1828.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 73%|███████▎  | 231/317 [11:03<03:41,  2.58s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.41 ms /    11 runs   (    2.04 ms per token,   490.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.87 ms /    94 tokens (   12.21 ms per token,    81.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1065.86 ms /    10 runs   (  106.59 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    2338.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 73%|███████▎  | 232/317 [11:07<04:18,  3.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.61 ms /    15 runs   (    2.04 ms per token,   489.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2336.78 ms /   223 tokens (   10.48 ms per token,    95.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1587.32 ms /    14 runs   (  113.38 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    4100.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 74%|███████▎  | 233/317 [11:09<03:44,  2.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      16.34 ms /     9 runs   (    1.82 ms per token,   550.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     893.15 ms /    28 tokens (   31.90 ms per token,    31.35 tokens per second)\n",
      "llama_print_timings:        eval time =     830.80 ms /     8 runs   (  103.85 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1825.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 74%|███████▍  | 234/317 [11:10<03:20,  2.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.18 ms /    10 runs   (    2.02 ms per token,   495.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.43 ms /    23 tokens (   33.45 ms per token,    29.89 tokens per second)\n",
      "llama_print_timings:        eval time =     927.33 ms /     9 runs   (  103.04 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1810.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 74%|███████▍  | 235/317 [11:13<03:25,  2.50s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      32.37 ms /    18 runs   (    1.80 ms per token,   556.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.82 ms /    49 tokens (   14.49 ms per token,    69.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1776.20 ms /    17 runs   (  104.48 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    2688.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 74%|███████▍  | 236/317 [11:15<03:09,  2.34s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.19 ms /    12 runs   (    2.02 ms per token,   496.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.05 ms /    19 tokens (   35.53 ms per token,    28.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.44 ms /    11 runs   (  103.40 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1948.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 75%|███████▍  | 237/317 [11:17<02:50,  2.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.79 ms /    10 runs   (    1.98 ms per token,   505.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.41 ms /    33 tokens (   18.29 ms per token,    54.69 tokens per second)\n",
      "llama_print_timings:        eval time =     939.56 ms /     9 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1656.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 75%|███████▌  | 238/317 [11:19<02:50,  2.16s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.36 ms /    14 runs   (    2.03 ms per token,   493.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.51 ms /    20 tokens (   35.08 ms per token,    28.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1345.92 ms /    13 runs   (  103.53 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2209.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 75%|███████▌  | 239/317 [11:21<02:37,  2.02s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.98 ms /    10 runs   (    2.00 ms per token,   500.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.90 ms /    36 tokens (   17.25 ms per token,    57.98 tokens per second)\n",
      "llama_print_timings:        eval time =     940.74 ms /     9 runs   (  104.53 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1676.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 76%|███████▌  | 240/317 [11:22<02:32,  1.98s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.95 ms /    11 runs   (    2.00 ms per token,   501.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.08 ms /    21 tokens (   34.62 ms per token,    28.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1027.63 ms /    10 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1879.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 76%|███████▌  | 241/317 [11:25<02:33,  2.02s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.76 ms /    10 runs   (    2.08 ms per token,   481.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.00 ms /    82 tokens (   12.93 ms per token,    77.36 tokens per second)\n",
      "llama_print_timings:        eval time =     952.66 ms /     9 runs   (  105.85 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    2126.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 76%|███████▋  | 242/317 [11:27<02:35,  2.07s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.78 ms /    15 runs   (    2.05 ms per token,   487.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     567.80 ms /    14 tokens (   40.56 ms per token,    24.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1436.45 ms /    14 runs   (  102.60 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    2175.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 77%|███████▋  | 243/317 [11:30<02:59,  2.43s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      37.61 ms /    20 runs   (    1.88 ms per token,   531.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.43 ms /    75 tokens (   13.73 ms per token,    72.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2010.30 ms /    19 runs   (  105.81 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    3268.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 77%|███████▋  | 244/317 [11:33<03:18,  2.72s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      50.69 ms /    24 runs   (    2.11 ms per token,   473.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.75 ms /    20 tokens (   35.54 ms per token,    28.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2408.93 ms /    23 runs   (  104.74 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    3401.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 77%|███████▋  | 245/317 [11:36<03:04,  2.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.76 ms /    13 runs   (    2.06 ms per token,   485.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.52 ms /    23 tokens (   33.50 ms per token,    29.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1243.77 ms /    12 runs   (  103.65 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2163.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 78%|███████▊  | 246/317 [11:38<02:49,  2.38s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.85 ms /    10 runs   (    2.09 ms per token,   479.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     914.39 ms /    30 tokens (   30.48 ms per token,    32.81 tokens per second)\n",
      "llama_print_timings:        eval time =     942.27 ms /     9 runs   (  104.70 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1974.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 78%|███████▊  | 247/317 [11:40<02:57,  2.53s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.05 ms /    15 runs   (    2.07 ms per token,   483.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1201.81 ms /    97 tokens (   12.39 ms per token,    80.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.12 ms /    14 runs   (  107.08 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    2873.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 78%|███████▊  | 248/317 [11:42<02:40,  2.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.29 ms /    10 runs   (    1.93 ms per token,   518.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.63 ms /    62 tokens (   12.72 ms per token,    78.62 tokens per second)\n",
      "llama_print_timings:        eval time =     948.77 ms /     9 runs   (  105.42 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1852.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 79%|███████▊  | 249/317 [11:45<02:55,  2.58s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.69 ms /    18 runs   (    1.93 ms per token,   518.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1103.43 ms /    88 tokens (   12.54 ms per token,    79.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1835.90 ms /    17 runs   (  107.99 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    3152.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 79%|███████▉  | 250/317 [11:49<03:14,  2.90s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.23 ms /    19 runs   (    2.22 ms per token,   449.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.65 ms /   108 tokens (   12.27 ms per token,    81.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2067.99 ms /    18 runs   (  114.89 ms per token,     8.70 tokens per second)\n",
      "llama_print_timings:       total time =    3646.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 79%|███████▉  | 251/317 [11:51<02:53,  2.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.17 ms /    12 runs   (    2.26 ms per token,   441.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.98 ms /    40 tokens (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1184.81 ms /    11 runs   (  107.71 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    1996.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 79%|███████▉  | 252/317 [11:53<02:36,  2.41s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.86 ms /    12 runs   (    2.07 ms per token,   482.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     622.02 ms /    16 tokens (   38.88 ms per token,    25.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.69 ms /    11 runs   (  103.15 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1894.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 80%|███████▉  | 253/317 [11:57<03:08,  2.94s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      40.55 ms /    22 runs   (    1.84 ms per token,   542.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1611.87 ms /   130 tokens (   12.40 ms per token,    80.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2311.28 ms /    21 runs   (  110.06 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    4176.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 80%|████████  | 254/317 [11:59<02:45,  2.62s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.28 ms /    11 runs   (    2.03 ms per token,   493.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.51 ms /    43 tokens (   15.90 ms per token,    62.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.00 ms /    10 runs   (  104.90 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1859.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 80%|████████  | 255/317 [12:01<02:28,  2.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.55 ms /    11 runs   (    1.78 ms per token,   562.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.71 ms /    50 tokens (   14.33 ms per token,    69.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1050.40 ms /    10 runs   (  105.04 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1890.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 81%|████████  | 256/317 [12:03<02:28,  2.43s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.83 ms /    16 runs   (    2.11 ms per token,   472.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.90 ms /    47 tokens (   15.00 ms per token,    66.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1587.73 ms /    15 runs   (  105.85 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    2483.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 81%|████████  | 257/317 [12:05<02:14,  2.24s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.08 ms /    10 runs   (    2.01 ms per token,   498.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.29 ms /    54 tokens (   13.69 ms per token,    73.04 tokens per second)\n",
      "llama_print_timings:        eval time =     940.39 ms /     9 runs   (  104.49 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1794.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 81%|████████▏ | 258/317 [12:12<03:24,  3.47s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      92.63 ms /    46 runs   (    2.01 ms per token,   496.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     990.93 ms /    68 tokens (   14.57 ms per token,    68.62 tokens per second)\n",
      "llama_print_timings:        eval time =    4799.19 ms /    45 runs   (  106.65 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    6322.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 82%|████████▏ | 259/317 [12:16<03:40,  3.80s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      40.04 ms /    22 runs   (    1.82 ms per token,   549.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1964.77 ms /   165 tokens (   11.91 ms per token,    83.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2356.94 ms /    21 runs   (  112.24 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    4577.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 82%|████████▏ | 260/317 [12:18<03:07,  3.29s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.63 ms /    13 runs   (    2.05 ms per token,   488.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.61 ms /    20 tokens (   34.88 ms per token,    28.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1238.67 ms /    12 runs   (  103.22 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    2086.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 82%|████████▏ | 261/317 [12:21<02:50,  3.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      35.03 ms /    17 runs   (    2.06 ms per token,   485.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.94 ms /    14 tokens (   42.71 ms per token,    23.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.33 ms /    16 runs   (  104.21 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2463.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 83%|████████▎ | 262/317 [12:23<02:32,  2.77s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.19 ms /    12 runs   (    2.02 ms per token,   496.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     856.96 ms /    27 tokens (   31.74 ms per token,    31.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.09 ms /    11 runs   (  104.01 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    2139.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 83%|████████▎ | 263/317 [12:25<02:15,  2.52s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.50 ms /    11 runs   (    2.14 ms per token,   468.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     758.49 ms /    23 tokens (   32.98 ms per token,    30.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1032.49 ms /    10 runs   (  103.25 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1917.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 83%|████████▎ | 264/317 [12:28<02:16,  2.58s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.29 ms /    15 runs   (    2.02 ms per token,   495.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1071.83 ms /    82 tokens (   13.07 ms per token,    76.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1486.94 ms /    14 runs   (  106.21 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    2731.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 84%|████████▎ | 265/317 [12:30<02:06,  2.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.19 ms /     9 runs   (    2.02 ms per token,   494.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1132.05 ms /    93 tokens (   12.17 ms per token,    82.15 tokens per second)\n",
      "llama_print_timings:        eval time =     851.19 ms /     8 runs   (  106.40 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    2085.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 84%|████████▍ | 266/317 [12:31<01:53,  2.22s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.81 ms /    10 runs   (    2.08 ms per token,   480.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.90 ms /    43 tokens (   15.53 ms per token,    64.38 tokens per second)\n",
      "llama_print_timings:        eval time =     940.77 ms /     9 runs   (  104.53 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1724.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 84%|████████▍ | 267/317 [12:34<02:03,  2.48s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.87 ms /    10 runs   (    2.19 ms per token,   457.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1903.07 ms /   161 tokens (   11.82 ms per token,    84.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1024.73 ms /     9 runs   (  113.86 ms per token,     8.78 tokens per second)\n",
      "llama_print_timings:       total time =    3060.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 85%|████████▍ | 268/317 [12:37<02:01,  2.47s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.57 ms /    16 runs   (    1.66 ms per token,   602.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.87 ms /    43 tokens (   15.81 ms per token,    63.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1586.81 ms /    15 runs   (  105.79 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    2447.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      " 85%|████████▍ | 269/317 [12:39<01:58,  2.47s/it]llama_print_timings:      sample time =      36.26 ms /    17 runs   (    2.13 ms per token,   468.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.40 ms /    14 tokens (   43.03 ms per token,    23.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.28 ms /    16 runs   (  104.20 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2471.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 85%|████████▌ | 270/317 [12:41<01:48,  2.31s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      25.40 ms /    12 runs   (    2.12 ms per token,   472.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.27 ms /    17 tokens (   38.19 ms per token,    26.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.62 ms /    11 runs   (  104.15 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1936.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 85%|████████▌ | 271/317 [12:43<01:40,  2.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.22 ms /    11 runs   (    2.11 ms per token,   473.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.28 ms /    20 tokens (   36.21 ms per token,    27.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.96 ms /    10 runs   (  104.60 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    1900.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      61.02 ms /    29 runs   (    2.10 ms per token,   475.22 tokens per second)\n",
      " 86%|████████▌ | 272/317 [12:47<02:05,  2.78s/it]llama_print_timings: prompt eval time =     803.11 ms /    61 tokens (   13.17 ms per token,    75.95 tokens per second)\n",
      "llama_print_timings:        eval time =    3001.81 ms /    28 runs   (  107.21 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    4149.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 86%|████████▌ | 273/317 [12:49<01:50,  2.52s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.57 ms /    12 runs   (    2.05 ms per token,   488.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     627.56 ms /    16 tokens (   39.22 ms per token,    25.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.55 ms /    11 runs   (  103.69 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1907.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 86%|████████▋ | 274/317 [12:51<01:39,  2.31s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.20 ms /    11 runs   (    2.02 ms per token,   495.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.56 ms /    17 tokens (   37.97 ms per token,    26.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1038.32 ms /    10 runs   (  103.83 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1811.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 87%|████████▋ | 275/317 [12:55<01:56,  2.77s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.75 ms /    16 runs   (    2.11 ms per token,   474.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1988.58 ms /   174 tokens (   11.43 ms per token,    87.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1659.62 ms /    15 runs   (  110.64 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    3834.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 87%|████████▋ | 276/317 [12:57<01:43,  2.52s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.26 ms /    12 runs   (    2.02 ms per token,   494.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.87 ms /    18 tokens (   37.10 ms per token,    26.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.12 ms /    11 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1945.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 87%|████████▋ | 277/317 [12:59<01:35,  2.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.12 ms /    13 runs   (    2.09 ms per token,   479.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.84 ms /    37 tokens (   17.59 ms per token,    56.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1259.98 ms /    12 runs   (  105.00 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    2061.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 88%|████████▊ | 278/317 [13:01<01:32,  2.38s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.24 ms /    15 runs   (    1.95 ms per token,   512.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.71 ms /    50 tokens (   14.41 ms per token,    69.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1474.48 ms /    14 runs   (  105.32 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    2367.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 88%|████████▊ | 279/317 [13:03<01:26,  2.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.48 ms /    11 runs   (    2.04 ms per token,   489.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.83 ms /    25 tokens (   33.11 ms per token,    30.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1040.54 ms /    10 runs   (  104.05 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1995.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 88%|████████▊ | 280/317 [13:06<01:29,  2.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.32 ms /    19 runs   (    2.02 ms per token,   495.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.16 ms /    18 tokens (   37.06 ms per token,    26.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1891.28 ms /    18 runs   (  105.07 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    2783.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 89%|████████▊ | 281/317 [13:08<01:23,  2.32s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.20 ms /    13 runs   (    2.09 ms per token,   477.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.88 ms /    17 tokens (   38.17 ms per token,    26.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.88 ms /    12 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2057.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 89%|████████▉ | 282/317 [13:14<01:56,  3.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      85.65 ms /    45 runs   (    1.90 ms per token,   525.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.90 ms /    15 tokens (   39.66 ms per token,    25.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4591.34 ms /    44 runs   (  104.35 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    5699.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 89%|████████▉ | 283/317 [13:19<02:14,  3.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      37.70 ms /    18 runs   (    2.09 ms per token,   477.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3209.39 ms /   284 tokens (   11.30 ms per token,    88.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1965.96 ms /    17 runs   (  115.64 ms per token,     8.65 tokens per second)\n",
      "llama_print_timings:       total time =    5388.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 90%|████████▉ | 284/317 [13:21<01:50,  3.35s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.31 ms /     9 runs   (    2.03 ms per token,   491.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     974.34 ms /    67 tokens (   14.54 ms per token,    68.76 tokens per second)\n",
      "llama_print_timings:        eval time =     847.43 ms /     8 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1925.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 90%|████████▉ | 285/317 [13:24<01:40,  3.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.60 ms /    11 runs   (    1.96 ms per token,   509.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.25 ms /   123 tokens (   11.36 ms per token,    88.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.23 ms /    10 runs   (  108.32 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    2605.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 90%|█████████ | 286/317 [13:28<01:44,  3.36s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.80 ms /    15 runs   (    2.12 ms per token,   471.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2161.94 ms /   196 tokens (   11.03 ms per token,    90.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1561.17 ms /    14 runs   (  111.51 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    3902.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 91%|█████████ | 287/317 [13:30<01:30,  3.00s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.32 ms /    14 runs   (    2.09 ms per token,   477.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.05 ms /    17 tokens (   37.89 ms per token,    26.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1347.82 ms /    13 runs   (  103.68 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2156.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 91%|█████████ | 288/317 [13:32<01:17,  2.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.05 ms /    11 runs   (    2.10 ms per token,   477.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.72 ms /    21 tokens (   34.51 ms per token,    28.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1035.31 ms /    10 runs   (  103.53 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1889.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 91%|█████████ | 289/317 [13:35<01:18,  2.80s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.15 ms /     9 runs   (    2.02 ms per token,   495.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2110.83 ms /   191 tokens (   11.05 ms per token,    90.49 tokens per second)\n",
      "llama_print_timings:        eval time =     892.54 ms /     8 runs   (  111.57 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    3106.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 91%|█████████▏| 290/317 [13:39<01:22,  3.07s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      55.35 ms /    27 runs   (    2.05 ms per token,   487.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.02 ms /    15 tokens (   40.47 ms per token,    24.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2754.30 ms /    26 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    3686.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 92%|█████████▏| 291/317 [13:40<01:10,  2.70s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.32 ms /    10 runs   (    2.03 ms per token,   492.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.36 ms /    58 tokens (   13.44 ms per token,    74.42 tokens per second)\n",
      "llama_print_timings:        eval time =     946.50 ms /     9 runs   (  105.17 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    1840.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 92%|█████████▏| 292/317 [13:42<01:02,  2.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.11 ms /    10 runs   (    2.01 ms per token,   497.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     922.90 ms /    29 tokens (   31.82 ms per token,    31.42 tokens per second)\n",
      "llama_print_timings:        eval time =     944.99 ms /     9 runs   (  105.00 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1984.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 92%|█████████▏| 293/317 [13:45<00:57,  2.38s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.55 ms /    11 runs   (    2.05 ms per token,   487.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     942.94 ms /    29 tokens (   32.52 ms per token,    30.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1046.45 ms /    10 runs   (  104.65 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2115.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 93%|█████████▎| 294/317 [13:47<00:55,  2.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.83 ms /    16 runs   (    2.11 ms per token,   472.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.34 ms /    42 tokens (   15.91 ms per token,    62.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1573.95 ms /    15 runs   (  104.93 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    2428.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 93%|█████████▎| 295/317 [13:56<01:33,  4.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     124.66 ms /    62 runs   (    2.01 ms per token,   497.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1243.21 ms /   101 tokens (   12.31 ms per token,    81.24 tokens per second)\n",
      "llama_print_timings:        eval time =    6638.86 ms /    61 runs   (  108.83 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =    8605.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 93%|█████████▎| 296/317 [14:02<01:44,  4.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     105.45 ms /    51 runs   (    2.07 ms per token,   483.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.18 ms /    48 tokens (   14.96 ms per token,    66.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5260.60 ms /    50 runs   (  105.21 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    6568.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 94%|█████████▎| 297/317 [14:05<01:24,  4.20s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.02 ms /    16 runs   (    2.06 ms per token,   484.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.06 ms /    21 tokens (   34.24 ms per token,    29.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1543.71 ms /    15 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    2447.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 94%|█████████▍| 298/317 [14:06<01:05,  3.45s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.68 ms /     9 runs   (    2.08 ms per token,   481.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.14 ms /    23 tokens (   33.22 ms per token,    30.10 tokens per second)\n",
      "llama_print_timings:        eval time =     832.66 ms /     8 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1700.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 94%|█████████▍| 299/317 [14:08<00:52,  2.93s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.35 ms /    11 runs   (    2.12 ms per token,   471.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     509.63 ms /    11 tokens (   46.33 ms per token,    21.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1052.56 ms /    10 runs   (  105.26 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    1697.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 95%|█████████▍| 300/317 [14:10<00:46,  2.72s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.31 ms /    14 runs   (    2.09 ms per token,   477.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.89 ms /    20 tokens (   34.74 ms per token,    28.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1351.76 ms /    13 runs   (  103.98 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    2215.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 95%|█████████▍| 301/317 [14:12<00:39,  2.47s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.74 ms /    11 runs   (    2.07 ms per token,   483.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.72 ms /    22 tokens (   33.17 ms per token,    30.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1027.31 ms /    10 runs   (  102.73 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1882.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      76.14 ms /    37 runs   (    2.06 ms per token,   485.95 tokens per second)\n",
      " 95%|█████████▌| 302/317 [14:17<00:48,  3.21s/it]llama_print_timings: prompt eval time =     753.67 ms /    23 tokens (   32.77 ms per token,    30.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3741.06 ms /    36 runs   (  103.92 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    4923.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 96%|█████████▌| 303/317 [14:19<00:38,  2.75s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.86 ms /    10 runs   (    2.09 ms per token,   479.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.44 ms /    16 tokens (   40.09 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:        eval time =     924.18 ms /     9 runs   (  102.69 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1680.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 96%|█████████▌| 304/317 [14:21<00:33,  2.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      25.47 ms /    13 runs   (    1.96 ms per token,   510.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.49 ms /    50 tokens (   14.25 ms per token,    70.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1246.16 ms /    12 runs   (  103.85 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    2106.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 96%|█████████▌| 305/317 [14:26<00:39,  3.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      72.85 ms /    38 runs   (    1.92 ms per token,   521.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.96 ms /    41 tokens (   15.95 ms per token,    62.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3878.51 ms /    37 runs   (  104.82 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    4966.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 97%|█████████▋| 306/317 [14:32<00:44,  4.06s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      89.02 ms /    45 runs   (    1.98 ms per token,   505.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.63 ms /    50 tokens (   14.33 ms per token,    69.77 tokens per second)\n",
      "llama_print_timings:        eval time =    4618.60 ms /    44 runs   (  104.97 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    5851.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 97%|█████████▋| 307/317 [14:34<00:34,  3.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.22 ms /    11 runs   (    1.84 ms per token,   544.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.13 ms /    51 tokens (   14.04 ms per token,    71.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1035.64 ms /    10 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1876.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 97%|█████████▋| 308/317 [14:37<00:31,  3.50s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.27 ms /    15 runs   (    2.02 ms per token,   495.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1993.27 ms /   181 tokens (   11.01 ms per token,    90.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1547.01 ms /    14 runs   (  110.50 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =    3712.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 97%|█████████▋| 309/317 [14:39<00:23,  2.96s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.92 ms /    10 runs   (    2.09 ms per token,   478.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.32 ms /    17 tokens (   37.61 ms per token,    26.59 tokens per second)\n",
      "llama_print_timings:        eval time =     937.58 ms /     9 runs   (  104.18 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1694.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 98%|█████████▊| 310/317 [14:41<00:19,  2.73s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.61 ms /    11 runs   (    2.15 ms per token,   466.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     975.59 ms /    68 tokens (   14.35 ms per token,    69.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1079.72 ms /    10 runs   (  107.97 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    2197.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 98%|█████████▊| 311/317 [14:45<00:17,  2.94s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.69 ms /    16 runs   (    1.98 ms per token,   504.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1605.81 ms /   130 tokens (   12.35 ms per token,    80.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1615.60 ms /    15 runs   (  107.71 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    3404.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 98%|█████████▊| 312/317 [14:47<00:13,  2.75s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.47 ms /    12 runs   (    1.87 ms per token,   533.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1026.44 ms /    75 tokens (   13.69 ms per token,    73.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.73 ms /    11 runs   (  105.25 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2321.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 99%|█████████▊| 313/317 [14:49<00:09,  2.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.96 ms /    10 runs   (    2.00 ms per token,   501.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     553.24 ms /    13 tokens (   42.56 ms per token,    23.50 tokens per second)\n",
      "llama_print_timings:        eval time =     917.36 ms /     9 runs   (  101.93 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1584.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 99%|█████████▉| 314/317 [14:52<00:08,  2.69s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      49.09 ms /    24 runs   (    2.05 ms per token,   488.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.56 ms /    45 tokens (   15.15 ms per token,    66.03 tokens per second)\n",
      "llama_print_timings:        eval time =    2403.90 ms /    23 runs   (  104.52 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    3363.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 99%|█████████▉| 315/317 [14:55<00:05,  2.90s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      45.96 ms /    23 runs   (    2.00 ms per token,   500.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     849.86 ms /    27 tokens (   31.48 ms per token,    31.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2275.60 ms /    22 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    3388.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "100%|█████████▉| 316/317 [14:57<00:02,  2.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.52 ms /    10 runs   (    1.95 ms per token,   512.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.42 ms /    47 tokens (   14.69 ms per token,    68.07 tokens per second)\n",
      "llama_print_timings:        eval time =     933.81 ms /     9 runs   (  103.76 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1739.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "100%|██████████| 317/317 [14:59<00:00,  2.37s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.49 ms /    10 runs   (    2.05 ms per token,   487.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     883.78 ms /    28 tokens (   31.56 ms per token,    31.68 tokens per second)\n",
      "llama_print_timings:        eval time =     936.70 ms /     9 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1937.07 ms\n",
      "100%|██████████| 317/317 [14:59<00:00,  2.84s/it]\n",
      "  0%|          | 0/96 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "  1%|          | 1/96 [00:04<06:30,  4.11s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      55.84 ms /    28 runs   (    1.99 ms per token,   501.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     950.48 ms /    31 tokens (   30.66 ms per token,    32.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2836.24 ms /    27 runs   (  105.05 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    4107.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  2%|▏         | 2/96 [00:05<04:03,  2.59s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.82 ms /    10 runs   (    2.08 ms per token,   480.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     466.96 ms /     9 tokens (   51.88 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =     932.34 ms /     9 runs   (  103.59 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1514.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  3%|▎         | 3/96 [00:07<03:29,  2.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.56 ms /    10 runs   (    1.96 ms per token,   511.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.74 ms /    60 tokens (   13.13 ms per token,    76.17 tokens per second)\n",
      "llama_print_timings:        eval time =     953.74 ms /     9 runs   (  105.97 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1855.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  4%|▍         | 4/96 [00:09<03:21,  2.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.62 ms /    13 runs   (    2.05 ms per token,   488.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.59 ms /    19 tokens (   36.40 ms per token,    27.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1252.51 ms /    12 runs   (  104.38 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    2093.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  5%|▌         | 5/96 [00:11<03:13,  2.12s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.78 ms /    13 runs   (    2.06 ms per token,   485.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.50 ms /    15 tokens (   40.03 ms per token,    24.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1246.41 ms /    12 runs   (  103.87 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1997.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  6%|▋         | 6/96 [00:13<03:06,  2.07s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.46 ms /    11 runs   (    2.04 ms per token,   489.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.05 ms /    23 tokens (   33.61 ms per token,    29.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1047.28 ms /    10 runs   (  104.73 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1948.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  7%|▋         | 7/96 [00:16<03:21,  2.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.00 ms /    15 runs   (    2.07 ms per token,   483.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.45 ms /    31 tokens (   32.53 ms per token,    30.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1477.10 ms /    14 runs   (  105.51 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    2659.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  8%|▊         | 8/96 [00:18<03:29,  2.38s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.31 ms /    18 runs   (    2.13 ms per token,   469.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.85 ms /    16 tokens (   39.55 ms per token,    25.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1783.47 ms /    17 runs   (  104.91 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    2630.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  9%|▉         | 9/96 [00:20<03:07,  2.16s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.66 ms /    10 runs   (    2.07 ms per token,   483.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.45 ms /    15 tokens (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:        eval time =     940.37 ms /     9 runs   (  104.49 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1667.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 10%|█         | 10/96 [00:24<03:46,  2.64s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      54.30 ms /    27 runs   (    2.01 ms per token,   497.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.49 ms /    37 tokens (   17.26 ms per token,    57.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2747.91 ms /    26 runs   (  105.69 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    3697.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 11%|█▏        | 11/96 [00:26<03:23,  2.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.43 ms /    11 runs   (    1.95 ms per token,   513.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.71 ms /    37 tokens (   17.40 ms per token,    57.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1061.35 ms /    10 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    1831.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 12%|█▎        | 12/96 [00:27<02:59,  2.14s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.66 ms /    11 runs   (    2.06 ms per token,   485.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.65 ms /     5 tokens (   75.53 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1040.00 ms /    10 runs   (  104.00 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1546.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 14%|█▎        | 13/96 [00:28<02:21,  1.70s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /     2 runs   (    2.05 ms per token,   487.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     562.42 ms /    13 tokens (   43.26 ms per token,    23.11 tokens per second)\n",
      "llama_print_timings:        eval time =     104.78 ms /     1 runs   (  104.78 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =     691.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     1 runs   (    2.05 ms per token,   487.57 tokens per second)\n",
      " 15%|█▍        | 14/96 [00:28<01:54,  1.39s/it]llama_print_timings: prompt eval time =     660.75 ms /    17 tokens (   38.87 ms per token,    25.73 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =     671.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 16%|█▌        | 15/96 [00:31<02:19,  1.72s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      39.04 ms /    19 runs   (    2.05 ms per token,   486.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.31 ms /     5 tokens (   75.46 ms per token,    13.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1872.58 ms /    18 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    2467.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 17%|█▋        | 16/96 [00:34<02:45,  2.07s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.09 ms /    21 runs   (    2.00 ms per token,   498.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     538.35 ms /    32 tokens (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2109.50 ms /    20 runs   (  105.47 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    2890.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 18%|█▊        | 17/96 [00:36<02:39,  2.02s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.74 ms /    12 runs   (    2.06 ms per token,   485.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.30 ms /    15 tokens (   40.42 ms per token,    24.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.76 ms /    11 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1890.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 19%|█▉        | 18/96 [00:39<03:00,  2.31s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.84 ms /    19 runs   (    2.04 ms per token,   489.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     850.42 ms /    25 tokens (   34.02 ms per token,    29.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1899.83 ms /    18 runs   (  105.55 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2975.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 20%|█▉        | 19/96 [00:41<02:54,  2.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.62 ms /    15 runs   (    2.04 ms per token,   489.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     522.49 ms /    11 tokens (   47.50 ms per token,    21.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1460.65 ms /    14 runs   (  104.33 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    2156.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 21%|██        | 20/96 [00:44<03:03,  2.41s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      35.98 ms /    18 runs   (    2.00 ms per token,   500.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     771.73 ms /    22 tokens (   35.08 ms per token,    28.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1776.56 ms /    17 runs   (  104.50 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    2754.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 22%|██▏       | 21/96 [00:50<04:26,  3.55s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      98.10 ms /    47 runs   (    2.09 ms per token,   479.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     782.47 ms /    23 tokens (   34.02 ms per token,    29.39 tokens per second)\n",
      "llama_print_timings:        eval time =    4868.15 ms /    46 runs   (  105.83 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    6207.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      " 23%|██▎       | 22/96 [00:57<05:42,  4.63s/it]llama_print_timings:      sample time =     107.55 ms /    51 runs   (    2.11 ms per token,   474.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.07 ms /    85 tokens (   13.09 ms per token,    76.37 tokens per second)\n",
      "llama_print_timings:        eval time =    5426.61 ms /    50 runs   (  108.53 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    7142.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 24%|██▍       | 23/96 [01:00<05:00,  4.12s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      37.88 ms /    19 runs   (    1.99 ms per token,   501.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     806.21 ms /    23 tokens (   35.05 ms per token,    28.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1893.12 ms /    18 runs   (  105.17 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2922.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 25%|██▌       | 24/96 [01:03<04:24,  3.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      35.08 ms /    18 runs   (    1.95 ms per token,   513.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.01 ms /    17 tokens (   38.06 ms per token,    26.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1760.84 ms /    17 runs   (  103.58 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2612.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 26%|██▌       | 25/96 [01:05<03:45,  3.17s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.69 ms /    11 runs   (    1.97 ms per token,   507.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.96 ms /    25 tokens (   33.44 ms per token,    29.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1041.24 ms /    10 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2002.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 27%|██▋       | 26/96 [01:07<03:16,  2.81s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.27 ms /    11 runs   (    2.02 ms per token,   493.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.30 ms /    23 tokens (   33.84 ms per token,    29.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1048.05 ms /    10 runs   (  104.81 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1954.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 28%|██▊       | 27/96 [01:08<02:54,  2.52s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.98 ms /    11 runs   (    2.00 ms per token,   500.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.02 ms /    40 tokens (   16.63 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1056.18 ms /    10 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    1849.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 29%|██▉       | 28/96 [01:19<05:38,  4.98s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     169.53 ms /    84 runs   (    2.02 ms per token,   495.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.53 ms /    58 tokens (   13.34 ms per token,    74.98 tokens per second)\n",
      "llama_print_timings:        eval time =    8934.80 ms /    83 runs   (  107.65 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =   10695.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 30%|███       | 29/96 [01:21<04:25,  3.97s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.87 ms /    10 runs   (    2.09 ms per token,   479.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     562.73 ms /    13 tokens (   43.29 ms per token,    23.10 tokens per second)\n",
      "llama_print_timings:        eval time =     937.06 ms /     9 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1616.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 31%|███▏      | 30/96 [01:23<03:40,  3.34s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.44 ms /    13 runs   (    2.03 ms per token,   491.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.61 ms /     9 tokens (   51.51 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1238.32 ms /    12 runs   (  103.19 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1850.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 32%|███▏      | 31/96 [01:24<03:07,  2.89s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.36 ms /    11 runs   (    2.03 ms per token,   491.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.91 ms /    19 tokens (   36.05 ms per token,    27.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1038.75 ms /    10 runs   (  103.88 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1849.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 33%|███▎      | 32/96 [01:31<04:20,  4.08s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     114.72 ms /    55 runs   (    2.09 ms per token,   479.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     555.11 ms /    13 tokens (   42.70 ms per token,    23.42 tokens per second)\n",
      "llama_print_timings:        eval time =    5647.26 ms /    54 runs   (  104.58 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    6841.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 34%|███▍      | 33/96 [01:33<03:38,  3.47s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.32 ms /    11 runs   (    2.03 ms per token,   492.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     889.33 ms /    28 tokens (   31.76 ms per token,    31.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1042.80 ms /    10 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    2058.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      81.53 ms /    39 runs   (    2.09 ms per token,   478.35 tokens per second)\n",
      " 35%|███▌      | 34/96 [01:38<04:01,  3.90s/it]llama_print_timings: prompt eval time =     467.14 ms /     9 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3972.16 ms /    38 runs   (  104.53 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    4894.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 36%|███▋      | 35/96 [01:40<03:13,  3.18s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.68 ms /     9 runs   (    2.08 ms per token,   481.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     538.76 ms /    32 tokens (   16.84 ms per token,    59.40 tokens per second)\n",
      "llama_print_timings:        eval time =     839.21 ms /     8 runs   (  104.90 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1484.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 38%|███▊      | 36/96 [01:45<03:43,  3.72s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      81.45 ms /    41 runs   (    1.99 ms per token,   503.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     353.91 ms /     4 tokens (   88.48 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4153.62 ms /    40 runs   (  103.84 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    4974.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 39%|███▊      | 37/96 [01:47<03:13,  3.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      32.80 ms /    16 runs   (    2.05 ms per token,   487.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     486.17 ms /    10 tokens (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1555.64 ms /    15 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2225.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 40%|███▉      | 38/96 [01:49<02:47,  2.89s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.23 ms /    11 runs   (    1.93 ms per token,   518.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.27 ms /    58 tokens (   13.38 ms per token,    74.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1072.98 ms /    10 runs   (  107.30 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    1987.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 41%|████      | 39/96 [01:51<02:33,  2.70s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.74 ms /    17 runs   (    2.04 ms per token,   489.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     382.31 ms /     5 tokens (   76.46 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1660.85 ms /    16 runs   (  103.80 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    2238.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 42%|████▏     | 40/96 [01:53<02:16,  2.43s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.02 ms /    11 runs   (    2.09 ms per token,   477.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.65 ms /    16 tokens (   39.73 ms per token,    25.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1042.96 ms /    10 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1807.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 43%|████▎     | 41/96 [01:57<02:36,  2.85s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      60.44 ms /    30 runs   (    2.01 ms per token,   496.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     466.40 ms /     9 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =    3019.17 ms /    29 runs   (  104.11 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    3830.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▍     | 42/96 [01:59<02:17,  2.54s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.68 ms /    11 runs   (    1.97 ms per token,   507.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.16 ms /    16 tokens (   39.45 ms per token,    25.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1053.71 ms /    10 runs   (  105.37 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1815.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 45%|████▍     | 43/96 [02:01<02:07,  2.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.91 ms /    11 runs   (    1.99 ms per token,   502.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     899.00 ms /    28 tokens (   32.11 ms per token,    31.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.81 ms /    10 runs   (  104.58 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2072.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 46%|████▌     | 44/96 [02:03<01:58,  2.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.68 ms /    12 runs   (    1.97 ms per token,   506.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.05 ms /    43 tokens (   15.63 ms per token,    63.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1159.11 ms /    11 runs   (  105.37 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1968.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 47%|████▋     | 45/96 [02:05<01:54,  2.25s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.21 ms /    12 runs   (    2.02 ms per token,   495.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     883.88 ms /    28 tokens (   31.57 ms per token,    31.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.16 ms /    11 runs   (  104.47 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    2171.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 48%|████▊     | 46/96 [02:07<01:50,  2.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.24 ms /    13 runs   (    2.10 ms per token,   477.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.32 ms /    47 tokens (   14.99 ms per token,    66.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1276.13 ms /    12 runs   (  106.34 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    2132.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 49%|████▉     | 47/96 [02:10<02:02,  2.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      41.11 ms /    21 runs   (    1.96 ms per token,   510.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.98 ms /    57 tokens (   13.58 ms per token,    73.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2128.21 ms /    20 runs   (  106.41 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    3142.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|█████     | 48/96 [02:12<01:49,  2.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.13 ms /    11 runs   (    2.01 ms per token,   497.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     624.11 ms /    16 tokens (   39.01 ms per token,    25.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1039.69 ms /    10 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1791.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 51%|█████     | 49/96 [02:14<01:41,  2.17s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.02 ms /    11 runs   (    2.00 ms per token,   499.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.78 ms /    50 tokens (   14.40 ms per token,    69.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.89 ms /    10 runs   (  104.99 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1896.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 52%|█████▏    | 50/96 [02:30<04:50,  6.32s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     250.35 ms /   128 runs   (    1.96 ms per token,   511.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.17 ms /    55 tokens (   13.68 ms per token,    73.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13767.88 ms /   127 runs   (  108.41 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =   16005.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 53%|█████▎    | 51/96 [02:32<03:52,  5.17s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      32.55 ms /    16 runs   (    2.03 ms per token,   491.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.63 ms /    19 tokens (   37.40 ms per token,    26.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1569.47 ms /    15 runs   (  104.63 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2465.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 54%|█████▍    | 52/96 [02:34<03:04,  4.20s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.00 ms /    11 runs   (    2.00 ms per token,   499.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.86 ms /    23 tokens (   33.65 ms per token,    29.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1033.82 ms /    10 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1933.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 55%|█████▌    | 53/96 [02:39<03:12,  4.47s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      75.30 ms /    38 runs   (    1.98 ms per token,   504.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.10 ms /    21 tokens (   34.77 ms per token,    28.76 tokens per second)\n",
      "llama_print_timings:        eval time =    3910.85 ms /    37 runs   (  105.70 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    5082.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▋    | 54/96 [02:45<03:26,  4.91s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      84.39 ms /    42 runs   (    2.01 ms per token,   497.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.29 ms /    78 tokens (   13.53 ms per token,    73.91 tokens per second)\n",
      "llama_print_timings:        eval time =    4393.05 ms /    41 runs   (  107.15 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    5933.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 57%|█████▋    | 55/96 [02:46<02:35,  3.79s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /     3 runs   (    2.22 ms per token,   451.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     932.38 ms /    30 tokens (   31.08 ms per token,    32.18 tokens per second)\n",
      "llama_print_timings:        eval time =     211.29 ms /     2 runs   (  105.64 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    1179.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 58%|█████▊    | 56/96 [02:49<02:12,  3.32s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.75 ms /    11 runs   (    1.98 ms per token,   505.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1024.39 ms /    73 tokens (   14.03 ms per token,    71.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1074.36 ms /    10 runs   (  107.44 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    2226.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 59%|█████▉    | 57/96 [02:51<01:54,  2.94s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.04 ms /    10 runs   (    2.00 ms per token,   499.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.56 ms /    31 tokens (   30.95 ms per token,    32.31 tokens per second)\n",
      "llama_print_timings:        eval time =     950.52 ms /     9 runs   (  105.61 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2025.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 60%|██████    | 58/96 [02:53<01:44,  2.75s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      25.22 ms /    12 runs   (    2.10 ms per token,   475.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     962.27 ms /    31 tokens (   31.04 ms per token,    32.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1190.58 ms /    11 runs   (  108.23 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =    2302.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 61%|██████▏   | 59/96 [02:55<01:28,  2.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.82 ms /     9 runs   (    1.98 ms per token,   504.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     613.86 ms /    34 tokens (   18.05 ms per token,    55.39 tokens per second)\n",
      "llama_print_timings:        eval time =     843.77 ms /     8 runs   (  105.47 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    1561.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 62%|██████▎   | 60/96 [02:56<01:18,  2.17s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.35 ms /    10 runs   (    2.03 ms per token,   491.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     583.16 ms /    14 tokens (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:        eval time =     938.08 ms /     9 runs   (  104.23 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1637.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 64%|██████▎   | 61/96 [02:58<01:10,  2.03s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.91 ms /    10 runs   (    2.09 ms per token,   478.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.07 ms /    34 tokens (   18.06 ms per token,    55.37 tokens per second)\n",
      "llama_print_timings:        eval time =     957.19 ms /     9 runs   (  106.35 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    1690.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 65%|██████▍   | 62/96 [03:04<01:51,  3.29s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      82.38 ms /    41 runs   (    2.01 ms per token,   497.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.17 ms /   123 tokens (   11.32 ms per token,    88.35 tokens per second)\n",
      "llama_print_timings:        eval time =    4364.09 ms /    40 runs   (  109.10 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    6227.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 66%|██████▌   | 63/96 [03:06<01:34,  2.86s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.79 ms /    13 runs   (    2.06 ms per token,   485.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     444.55 ms /     8 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1252.92 ms /    12 runs   (  104.41 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1848.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 67%|██████▋   | 64/96 [03:11<01:50,  3.45s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      72.16 ms /    36 runs   (    2.00 ms per token,   498.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.86 ms /    43 tokens (   15.76 ms per token,    63.43 tokens per second)\n",
      "llama_print_timings:        eval time =    3716.06 ms /    35 runs   (  106.17 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    4810.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 68%|██████▊   | 65/96 [03:13<01:32,  3.00s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.67 ms /    10 runs   (    2.07 ms per token,   483.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     885.36 ms /    28 tokens (   31.62 ms per token,    31.63 tokens per second)\n",
      "llama_print_timings:        eval time =     944.64 ms /     9 runs   (  104.96 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1944.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 69%|██████▉   | 66/96 [03:15<01:18,  2.61s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.46 ms /    10 runs   (    1.95 ms per token,   513.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.79 ms /    37 tokens (   17.26 ms per token,    57.92 tokens per second)\n",
      "llama_print_timings:        eval time =     942.28 ms /     9 runs   (  104.70 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1693.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 70%|██████▉   | 67/96 [03:17<01:10,  2.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.68 ms /    14 runs   (    2.05 ms per token,   488.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     464.24 ms /     9 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1354.27 ms /    13 runs   (  104.17 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1979.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 71%|███████   | 68/96 [03:19<01:05,  2.33s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.27 ms /    14 runs   (    2.02 ms per token,   495.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     577.67 ms /    14 tokens (   41.26 ms per token,    24.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1357.29 ms /    13 runs   (  104.41 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    2100.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 72%|███████▏  | 69/96 [03:24<01:27,  3.23s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      73.80 ms /    38 runs   (    1.94 ms per token,   514.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     970.93 ms /    31 tokens (   31.32 ms per token,    31.93 tokens per second)\n",
      "llama_print_timings:        eval time =    3911.74 ms /    37 runs   (  105.72 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    5322.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 73%|███████▎  | 70/96 [03:27<01:19,  3.06s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      39.44 ms /    19 runs   (    2.08 ms per token,   481.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     565.24 ms /    13 tokens (   43.48 ms per token,    23.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1871.06 ms /    18 runs   (  103.95 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    2657.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 74%|███████▍  | 71/96 [03:30<01:22,  3.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      52.26 ms /    26 runs   (    2.01 ms per token,   497.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     881.40 ms /    28 tokens (   31.48 ms per token,    31.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2622.31 ms /    25 runs   (  104.89 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    3804.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 75%|███████▌  | 72/96 [03:32<01:07,  2.83s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      17.88 ms /    10 runs   (    1.79 ms per token,   559.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.09 ms /    46 tokens (   15.18 ms per token,    65.89 tokens per second)\n",
      "llama_print_timings:        eval time =     946.56 ms /     9 runs   (  105.17 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    1757.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 76%|███████▌  | 73/96 [03:34<00:57,  2.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.39 ms /    11 runs   (    2.04 ms per token,   491.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     536.86 ms /    12 tokens (   44.74 ms per token,    22.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.11 ms /    10 runs   (  104.51 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1707.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 77%|███████▋  | 74/96 [03:36<00:50,  2.31s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.53 ms /     9 runs   (    2.06 ms per token,   485.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     922.41 ms /    29 tokens (   31.81 ms per token,    31.44 tokens per second)\n",
      "llama_print_timings:        eval time =     839.20 ms /     8 runs   (  104.90 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1866.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 78%|███████▊  | 75/96 [03:37<00:40,  1.94s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      14.69 ms /     7 runs   (    2.10 ms per token,   476.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.56 ms /     5 tokens (   75.51 ms per token,    13.24 tokens per second)\n",
      "llama_print_timings:        eval time =     628.96 ms /     6 runs   (  104.83 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1088.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 79%|███████▉  | 76/96 [03:40<00:44,  2.23s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      39.63 ms /    19 runs   (    2.09 ms per token,   479.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.17 ms /    53 tokens (   13.93 ms per token,    71.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1915.63 ms /    18 runs   (  106.42 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    2879.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 80%|████████  | 77/96 [03:41<00:38,  2.05s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.04 ms /     9 runs   (    2.00 ms per token,   499.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.94 ms /    19 tokens (   36.63 ms per token,    27.30 tokens per second)\n",
      "llama_print_timings:        eval time =     836.06 ms /     8 runs   (  104.51 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1635.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 81%|████████▏ | 78/96 [03:43<00:36,  2.02s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.25 ms /    13 runs   (    2.02 ms per token,   495.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     545.56 ms /    12 tokens (   45.46 ms per token,    22.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1245.81 ms /    12 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1940.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 82%|████████▏ | 79/96 [03:45<00:33,  1.99s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.25 ms /    14 runs   (    2.02 ms per token,   495.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.55 ms /     6 tokens (   66.76 ms per token,    14.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1344.29 ms /    13 runs   (  103.41 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1904.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 83%|████████▎ | 80/96 [03:47<00:31,  1.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.32 ms /    10 runs   (    1.93 ms per token,   517.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     800.84 ms /    62 tokens (   12.92 ms per token,    77.42 tokens per second)\n",
      "llama_print_timings:        eval time =     957.96 ms /     9 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    1873.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 84%|████████▍ | 81/96 [03:53<00:44,  2.99s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      82.39 ms /    41 runs   (    2.01 ms per token,   497.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.04 ms /    40 tokens (   16.53 ms per token,    60.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4272.12 ms /    40 runs   (  106.80 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    5416.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 85%|████████▌ | 82/96 [03:56<00:44,  3.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      54.86 ms /    27 runs   (    2.03 ms per token,   492.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.74 ms /    16 tokens (   39.48 ms per token,    25.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2742.85 ms /    26 runs   (  105.49 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    3691.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      " 86%|████████▋ | 83/96 [04:00<00:45,  3.46s/it]llama_print_timings:      sample time =      41.69 ms /    21 runs   (    1.99 ms per token,   503.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1612.93 ms /   130 tokens (   12.41 ms per token,    80.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2193.83 ms /    20 runs   (  109.69 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =    4058.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 88%|████████▊ | 84/96 [04:04<00:41,  3.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.47 ms /    22 runs   (    1.98 ms per token,   506.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.06 ms /    48 tokens (   14.96 ms per token,    66.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2373.27 ms /    21 runs   (  113.01 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =    3376.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 89%|████████▊ | 85/96 [04:06<00:34,  3.10s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.36 ms /    12 runs   (    2.03 ms per token,   492.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     989.78 ms /    30 tokens (   32.99 ms per token,    30.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.64 ms /    11 runs   (  105.24 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2286.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 90%|████████▉ | 86/96 [04:08<00:28,  2.86s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      30.54 ms /    16 runs   (    1.91 ms per token,   523.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     540.38 ms /    32 tokens (   16.89 ms per token,    59.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1592.70 ms /    15 runs   (  106.18 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    2317.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 91%|█████████ | 87/96 [04:10<00:22,  2.54s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.56 ms /    11 runs   (    2.05 ms per token,   487.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.59 ms /    15 tokens (   39.97 ms per token,    25.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1044.36 ms /    10 runs   (  104.44 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1772.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 92%|█████████▏| 88/96 [04:12<00:18,  2.32s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.18 ms /    14 runs   (    2.08 ms per token,   479.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.31 ms /     2 tokens (  142.66 ms per token,     7.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1355.76 ms /    13 runs   (  104.29 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1804.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 93%|█████████▎| 89/96 [04:28<00:45,  6.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     264.72 ms /   128 runs   (    2.07 ms per token,   483.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.68 ms /    24 tokens (   34.07 ms per token,    29.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13701.47 ms /   127 runs   (  107.89 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =   16039.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 94%|█████████▍| 90/96 [04:29<00:29,  4.97s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.31 ms /     9 runs   (    2.03 ms per token,   491.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.75 ms /    15 tokens (   40.72 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:        eval time =     834.86 ms /     8 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1551.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 95%|█████████▍| 91/96 [04:32<00:21,  4.34s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      41.00 ms /    20 runs   (    2.05 ms per token,   487.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.41 ms /    33 tokens (   18.44 ms per token,    54.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2025.58 ms /    19 runs   (  106.61 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    2871.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 96%|█████████▌| 92/96 [04:34<00:14,  3.58s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.78 ms /     9 runs   (    2.09 ms per token,   479.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     837.31 ms /    25 tokens (   33.49 ms per token,    29.86 tokens per second)\n",
      "llama_print_timings:        eval time =     849.06 ms /     8 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    1794.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 97%|█████████▋| 93/96 [04:36<00:09,  3.01s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.23 ms /    10 runs   (    2.12 ms per token,   470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.01 ms /    14 tokens (   43.64 ms per token,    22.91 tokens per second)\n",
      "llama_print_timings:        eval time =     948.46 ms /     9 runs   (  105.38 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1680.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 98%|█████████▊| 94/96 [04:38<00:05,  2.89s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.91 ms /    16 runs   (    2.12 ms per token,   471.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.16 ms /    23 tokens (   35.70 ms per token,    28.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1582.36 ms /    15 runs   (  105.49 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    2594.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 99%|█████████▉| 95/96 [04:40<00:02,  2.45s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.83 ms /    10 runs   (    2.08 ms per token,   480.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     382.36 ms /     5 tokens (   76.47 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:        eval time =     937.78 ms /     9 runs   (  104.20 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1435.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "100%|██████████| 96/96 [04:42<00:00,  2.25s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.10 ms /    10 runs   (    2.11 ms per token,   474.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.43 ms /    44 tokens (   15.51 ms per token,    64.48 tokens per second)\n",
      "llama_print_timings:        eval time =     952.92 ms /     9 runs   (  105.88 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1754.39 ms\n",
      "100%|██████████| 96/96 [04:42<00:00,  2.94s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "  6%|▌         | 1/18 [00:02<00:34,  2.04s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.85 ms /    11 runs   (    1.99 ms per token,   503.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.68 ms /    61 tokens (   13.58 ms per token,    73.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1078.80 ms /    10 runs   (  107.88 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    2034.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 11%|█         | 2/18 [00:04<00:39,  2.46s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.09 ms /    17 runs   (    2.01 ms per token,   498.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     821.93 ms /    61 tokens (   13.47 ms per token,    74.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1730.10 ms /    16 runs   (  108.13 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    2746.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 17%|█▋        | 3/18 [00:08<00:42,  2.85s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      40.24 ms /    20 runs   (    2.01 ms per token,   497.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     995.15 ms /    65 tokens (   15.31 ms per token,    65.32 tokens per second)\n",
      "llama_print_timings:        eval time =    2087.11 ms /    19 runs   (  109.85 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    3317.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 22%|██▏       | 4/18 [00:10<00:36,  2.58s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.03 ms /    13 runs   (    2.08 ms per token,   480.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.72 ms /    18 tokens (   39.48 ms per token,    25.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.49 ms /    12 runs   (  107.62 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    2156.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 28%|██▊       | 5/18 [00:15<00:44,  3.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      62.96 ms /    32 runs   (    1.97 ms per token,   508.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1094.13 ms /    76 tokens (   14.40 ms per token,    69.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3439.81 ms /    31 runs   (  110.96 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    4908.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 33%|███▎      | 6/18 [00:21<00:50,  4.24s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      84.85 ms /    43 runs   (    1.97 ms per token,   506.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.15 ms /    44 tokens (   16.07 ms per token,    62.22 tokens per second)\n",
      "llama_print_timings:        eval time =    4616.83 ms /    42 runs   (  109.92 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    5833.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 39%|███▉      | 7/18 [00:23<00:38,  3.54s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.22 ms /    16 runs   (    2.08 ms per token,   481.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.54 ms /     2 tokens (  145.27 ms per token,     6.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1595.49 ms /    15 runs   (  106.37 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    2073.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▍     | 8/18 [00:26<00:33,  3.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      41.45 ms /    20 runs   (    2.07 ms per token,   482.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.25 ms /    21 tokens (   37.44 ms per token,    26.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2051.13 ms /    19 runs   (  107.95 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =    3077.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|█████     | 9/18 [00:28<00:26,  2.93s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.59 ms /    11 runs   (    2.05 ms per token,   486.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.64 ms /    42 tokens (   16.68 ms per token,    59.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1077.51 ms /    10 runs   (  107.75 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    1907.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▌    | 10/18 [00:28<00:18,  2.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /     1 runs   (    2.03 ms per token,   491.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.66 ms /    19 tokens (   38.35 ms per token,    26.08 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =     740.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 61%|██████    | 11/18 [00:30<00:15,  2.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.32 ms /    12 runs   (    1.94 ms per token,   514.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.45 ms /    48 tokens (   15.01 ms per token,    66.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1183.69 ms /    11 runs   (  107.61 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    2043.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 67%|██████▋   | 12/18 [00:36<00:18,  3.09s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      69.03 ms /    33 runs   (    2.09 ms per token,   478.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1241.03 ms /    97 tokens (   12.79 ms per token,    78.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3524.94 ms /    32 runs   (  110.15 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    5152.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 72%|███████▏  | 13/18 [00:37<00:13,  2.62s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /     1 runs   (    1.85 ms per token,   540.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1519.38 ms /   128 tokens (   11.87 ms per token,    84.25 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    1531.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 78%|███████▊  | 14/18 [00:40<00:10,  2.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.33 ms /    15 runs   (    1.96 ms per token,   511.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1062.92 ms /    76 tokens (   13.99 ms per token,    71.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1524.60 ms /    14 runs   (  108.90 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    2760.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 83%|████████▎ | 15/18 [00:45<00:10,  3.55s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      72.14 ms /    37 runs   (    1.95 ms per token,   512.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.75 ms /    91 tokens (   13.11 ms per token,    76.29 tokens per second)\n",
      "llama_print_timings:        eval time =    3961.85 ms /    36 runs   (  110.05 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    5580.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 89%|████████▉ | 16/18 [00:47<00:05,  2.91s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.68 ms /     9 runs   (    2.08 ms per token,   481.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     467.20 ms /     8 tokens (   58.40 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =     847.43 ms /     8 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1419.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 94%|█████████▍| 17/18 [00:49<00:02,  2.60s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.75 ms /    10 runs   (    2.08 ms per token,   481.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     767.40 ms /    54 tokens (   14.21 ms per token,    70.37 tokens per second)\n",
      "llama_print_timings:        eval time =     984.34 ms /     9 runs   (  109.37 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    1869.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "100%|██████████| 18/18 [00:51<00:00,  2.43s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.35 ms /    11 runs   (    2.03 ms per token,   492.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.79 ms /    56 tokens (   14.59 ms per token,    68.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.32 ms /    10 runs   (  108.63 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    2034.06 ms\n",
      "100%|██████████| 18/18 [00:51<00:00,  2.85s/it]\n",
      "  0%|          | 0/105 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "  1%|          | 1/105 [00:02<04:42,  2.72s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      35.36 ms /    18 runs   (    1.96 ms per token,   509.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.67 ms /    33 tokens (   19.32 ms per token,    51.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1868.69 ms /    17 runs   (  109.92 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    2714.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  2%|▏         | 2/105 [00:04<04:07,  2.41s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      27.25 ms /    13 runs   (    2.10 ms per token,   477.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     714.76 ms /    17 tokens (   42.04 ms per token,    23.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.01 ms /    12 runs   (  108.67 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =    2178.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  3%|▎         | 3/105 [00:07<04:14,  2.50s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      37.49 ms /    18 runs   (    2.08 ms per token,   480.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     531.13 ms /    10 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1853.63 ms /    17 runs   (  109.04 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    2596.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  4%|▍         | 4/105 [00:11<04:58,  2.95s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      49.02 ms /    24 runs   (    2.04 ms per token,   489.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     820.21 ms /    22 tokens (   37.28 ms per token,    26.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2544.18 ms /    23 runs   (  110.62 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    3649.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  5%|▍         | 5/105 [00:13<04:24,  2.65s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.59 ms /    11 runs   (    2.05 ms per token,   486.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     852.84 ms /    61 tokens (   13.98 ms per token,    71.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.45 ms /    10 runs   (  111.54 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =    2097.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  6%|▌         | 6/105 [00:15<04:22,  2.65s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.36 ms /    14 runs   (    2.10 ms per token,   476.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.67 ms /    29 tokens (   35.85 ms per token,    27.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1434.93 ms /    13 runs   (  110.38 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    2639.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  7%|▋         | 7/105 [00:22<06:17,  3.85s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      95.96 ms /    46 runs   (    2.09 ms per token,   479.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.50 ms /    21 tokens (   39.40 ms per token,    25.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4956.23 ms /    45 runs   (  110.14 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    6327.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  8%|▊         | 8/105 [00:23<05:05,  3.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.02 ms /     9 runs   (    2.00 ms per token,   499.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.54 ms /    38 tokens (   17.75 ms per token,    56.33 tokens per second)\n",
      "llama_print_timings:        eval time =     875.49 ms /     8 runs   (  109.44 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    1655.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "  9%|▊         | 9/105 [00:27<05:02,  3.15s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.94 ms /    17 runs   (    2.00 ms per token,   500.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.04 ms /    78 tokens (   14.63 ms per token,    68.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1781.86 ms /    16 runs   (  111.37 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    3120.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 10%|▉         | 10/105 [00:29<04:27,  2.82s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.79 ms /    13 runs   (    2.06 ms per token,   485.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     617.02 ms /    13 tokens (   47.46 ms per token,    21.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.59 ms /    12 runs   (  109.05 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    2078.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 10%|█         | 11/105 [00:30<03:54,  2.50s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.61 ms /     9 runs   (    2.18 ms per token,   458.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.52 ms /    18 tokens (   42.97 ms per token,    23.27 tokens per second)\n",
      "llama_print_timings:        eval time =     881.42 ms /     8 runs   (  110.18 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    1765.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 11%|█▏        | 12/105 [00:32<03:39,  2.36s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.05 ms /    11 runs   (    2.00 ms per token,   498.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.96 ms /    21 tokens (   39.24 ms per token,    25.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.02 ms /    10 runs   (  109.10 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    2042.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 12%|█▏        | 13/105 [00:36<04:03,  2.64s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.01 ms /    20 runs   (    2.15 ms per token,   465.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.66 ms /    26 tokens (   36.49 ms per token,    27.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2104.53 ms /    19 runs   (  110.76 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    3289.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 13%|█▎        | 14/105 [00:44<06:32,  4.31s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     121.39 ms /    62 runs   (    1.96 ms per token,   510.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.42 ms /    17 tokens (   42.73 ms per token,    23.40 tokens per second)\n",
      "llama_print_timings:        eval time =    6707.48 ms /    61 runs   (  109.96 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    8157.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 14%|█▍        | 15/105 [00:51<07:50,  5.23s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     110.00 ms /    57 runs   (    1.93 ms per token,   518.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     554.75 ms /    11 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:        eval time =    6122.71 ms /    56 runs   (  109.33 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =    7336.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 15%|█▌        | 16/105 [00:53<06:24,  4.32s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.63 ms /    14 runs   (    2.12 ms per token,   472.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.81 ms /    14 tokens (   45.20 ms per token,    22.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.32 ms /    13 runs   (  108.95 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    2213.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 16%|█▌        | 17/105 [00:56<05:27,  3.73s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.28 ms /    11 runs   (    2.03 ms per token,   493.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.38 ms /    31 tokens (   36.08 ms per token,    27.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.38 ms /    10 runs   (  109.14 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    2335.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 17%|█▋        | 18/105 [00:58<04:31,  3.13s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.74 ms /    12 runs   (    2.06 ms per token,   485.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     392.81 ms /     5 tokens (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1190.99 ms /    11 runs   (  108.27 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =    1724.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 18%|█▊        | 19/105 [00:59<03:54,  2.73s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.66 ms /    13 runs   (    2.05 ms per token,   487.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.13 ms /     3 tokens (  108.71 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1307.67 ms /    12 runs   (  108.97 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    1786.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 19%|█▉        | 20/105 [01:03<04:19,  3.06s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      49.71 ms /    25 runs   (    1.99 ms per token,   502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.55 ms /    59 tokens (   14.16 ms per token,    70.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2696.20 ms /    24 runs   (  112.34 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =    3825.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 20%|██        | 21/105 [01:08<04:53,  3.49s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      70.28 ms /    33 runs   (    2.13 ms per token,   469.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     576.52 ms /    11 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =    3531.22 ms /    32 runs   (  110.35 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    4501.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 21%|██        | 22/105 [01:10<04:15,  3.08s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.49 ms /    11 runs   (    2.04 ms per token,   489.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     879.07 ms /    23 tokens (   38.22 ms per token,    26.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.86 ms /    10 runs   (  109.79 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    2105.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 22%|██▏       | 23/105 [01:11<03:37,  2.65s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.52 ms /    10 runs   (    2.05 ms per token,   487.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     559.66 ms /    11 tokens (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_print_timings:        eval time =     980.09 ms /     9 runs   (  108.90 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    1657.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 23%|██▎       | 24/105 [01:14<03:23,  2.51s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.21 ms /    11 runs   (    2.11 ms per token,   473.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.88 ms /    25 tokens (   37.36 ms per token,    26.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.34 ms /    10 runs   (  110.03 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    2163.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 24%|██▍       | 25/105 [01:15<03:02,  2.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.13 ms /    11 runs   (    2.01 ms per token,   497.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     501.85 ms /     9 tokens (   55.76 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.45 ms /    10 runs   (  109.24 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =    1725.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 25%|██▍       | 26/105 [01:18<03:00,  2.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      25.40 ms /    13 runs   (    1.95 ms per token,   511.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.40 ms /    56 tokens (   14.35 ms per token,    69.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.92 ms /    12 runs   (  110.58 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    2282.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 26%|██▌       | 27/105 [01:19<02:43,  2.09s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.54 ms /    10 runs   (    2.05 ms per token,   486.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     552.51 ms /    11 tokens (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:        eval time =     982.24 ms /     9 runs   (  109.14 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    1654.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 27%|██▋       | 28/105 [01:22<03:06,  2.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      44.22 ms /    21 runs   (    2.11 ms per token,   474.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.97 ms /    18 tokens (   41.28 ms per token,    24.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2194.54 ms /    20 runs   (  109.73 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    3185.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 28%|██▊       | 29/105 [01:24<02:46,  2.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.50 ms /     9 runs   (    2.06 ms per token,   486.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.96 ms /    15 tokens (   44.00 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:        eval time =     872.36 ms /     8 runs   (  109.04 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    1638.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 29%|██▊       | 30/105 [01:31<04:30,  3.61s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     108.07 ms /    53 runs   (    2.04 ms per token,   490.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.93 ms /    12 tokens (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5698.23 ms /    52 runs   (  109.58 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    6926.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 30%|██▉       | 31/105 [01:36<04:54,  3.97s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      68.85 ms /    33 runs   (    2.09 ms per token,   479.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.15 ms /    23 tokens (   37.66 ms per token,    26.55 tokens per second)\n",
      "llama_print_timings:        eval time =    3545.70 ms /    32 runs   (  110.80 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    4809.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 30%|███       | 32/105 [01:42<05:32,  4.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      88.92 ms /    43 runs   (    2.07 ms per token,   483.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.54 ms /    49 tokens (   15.56 ms per token,    64.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4653.15 ms /    42 runs   (  110.79 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    5917.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 31%|███▏      | 33/105 [01:44<04:33,  3.80s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.40 ms /    11 runs   (    2.13 ms per token,   470.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.41 ms /    53 tokens (   14.97 ms per token,    66.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.94 ms /    10 runs   (  109.99 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    2023.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 32%|███▏      | 34/105 [01:46<03:52,  3.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.38 ms /     9 runs   (    2.04 ms per token,   489.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.60 ms /    29 tokens (   36.16 ms per token,    27.66 tokens per second)\n",
      "llama_print_timings:        eval time =     878.82 ms /     8 runs   (  109.85 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    2032.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 33%|███▎      | 35/105 [01:48<03:23,  2.91s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.44 ms /    14 runs   (    2.10 ms per token,   475.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     470.68 ms /     8 tokens (   58.83 ms per token,    17.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1410.23 ms /    13 runs   (  108.48 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    2046.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 34%|███▍      | 36/105 [01:55<04:45,  4.14s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     105.40 ms /    53 runs   (    1.99 ms per token,   502.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.13 ms /    35 tokens (   18.69 ms per token,    53.51 tokens per second)\n",
      "llama_print_timings:        eval time =    5746.94 ms /    52 runs   (  110.52 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =    7018.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 35%|███▌      | 37/105 [01:57<03:54,  3.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.04 ms /     9 runs   (    2.00 ms per token,   499.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     812.70 ms /    57 tokens (   14.26 ms per token,    70.14 tokens per second)\n",
      "llama_print_timings:        eval time =     882.47 ms /     8 runs   (  110.31 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    1802.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 36%|███▌      | 38/105 [02:00<03:38,  3.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.93 ms /    17 runs   (    2.05 ms per token,   486.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     894.21 ms /    24 tokens (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1746.36 ms /    16 runs   (  109.15 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    2839.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 37%|███▋      | 39/105 [02:02<03:11,  2.90s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.30 ms /    10 runs   (    2.03 ms per token,   492.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     950.54 ms /    27 tokens (   35.21 ms per token,    28.40 tokens per second)\n",
      "llama_print_timings:        eval time =     986.13 ms /     9 runs   (  109.57 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    2054.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 38%|███▊      | 40/105 [02:06<03:27,  3.19s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      54.54 ms /    26 runs   (    2.10 ms per token,   476.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.16 ms /    17 tokens (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2813.85 ms /    25 runs   (  112.55 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =    3842.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 39%|███▉      | 41/105 [02:07<02:53,  2.71s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.45 ms /     9 runs   (    2.05 ms per token,   487.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.56 ms /    13 tokens (   47.74 ms per token,    20.95 tokens per second)\n",
      "llama_print_timings:        eval time =     876.84 ms /     8 runs   (  109.60 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =    1603.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 40%|████      | 42/105 [02:10<02:59,  2.84s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.22 ms /    17 runs   (    1.95 ms per token,   511.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.32 ms /    79 tokens (   14.62 ms per token,    68.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1786.03 ms /    16 runs   (  111.63 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    3142.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 41%|████      | 43/105 [02:12<02:41,  2.61s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      29.20 ms /    14 runs   (    2.09 ms per token,   479.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     478.79 ms /     8 tokens (   59.85 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1420.54 ms /    13 runs   (  109.27 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =    2065.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 42%|████▏     | 44/105 [02:21<04:28,  4.41s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     127.50 ms /    65 runs   (    1.96 ms per token,   509.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.98 ms /    17 tokens (   42.82 ms per token,    23.35 tokens per second)\n",
      "llama_print_timings:        eval time =    7098.01 ms /    64 runs   (  110.91 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    8596.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 43%|████▎     | 45/105 [02:23<03:39,  3.66s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.32 ms /    10 runs   (    2.03 ms per token,   492.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.72 ms /    20 tokens (   40.14 ms per token,    24.92 tokens per second)\n",
      "llama_print_timings:        eval time =     974.75 ms /     9 runs   (  108.31 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    1893.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 44%|████▍     | 46/105 [02:25<03:13,  3.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      32.88 ms /    16 runs   (    2.06 ms per token,   486.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     575.18 ms /    12 tokens (   47.93 ms per token,    20.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1631.92 ms /    15 runs   (  108.79 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =    2400.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 45%|████▍     | 47/105 [02:29<03:11,  3.30s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.44 ms /    21 runs   (    2.07 ms per token,   483.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     888.91 ms /    24 tokens (   37.04 ms per token,    27.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2195.72 ms /    20 runs   (  109.79 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    3331.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 46%|████▌     | 48/105 [02:30<02:41,  2.83s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.43 ms /    10 runs   (    2.04 ms per token,   489.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.71 ms /    33 tokens (   19.48 ms per token,    51.35 tokens per second)\n",
      "llama_print_timings:        eval time =     986.84 ms /     9 runs   (  109.65 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =    1745.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 47%|████▋     | 49/105 [02:32<02:25,  2.60s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.95 ms /    10 runs   (    2.00 ms per token,   501.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.10 ms /    27 tokens (   35.52 ms per token,    28.15 tokens per second)\n",
      "llama_print_timings:        eval time =     985.93 ms /     9 runs   (  109.55 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    2060.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 48%|████▊     | 50/105 [02:38<03:19,  3.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      93.74 ms /    45 runs   (    2.08 ms per token,   480.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.45 ms /    13 tokens (   46.65 ms per token,    21.44 tokens per second)\n",
      "llama_print_timings:        eval time =    4863.27 ms /    44 runs   (  110.53 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =    6004.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 49%|████▊     | 51/105 [02:42<03:16,  3.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.28 ms /    22 runs   (    1.97 ms per token,   508.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1080.12 ms /    30 tokens (   36.00 ms per token,    27.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2306.63 ms /    21 runs   (  109.84 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    3640.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|████▉     | 52/105 [02:44<02:42,  3.06s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.40 ms /    10 runs   (    2.04 ms per token,   490.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.05 ms /    14 tokens (   45.50 ms per token,    21.98 tokens per second)\n",
      "llama_print_timings:        eval time =     977.52 ms /     9 runs   (  108.61 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    1730.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 50%|█████     | 53/105 [02:47<02:39,  3.08s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      43.99 ms /    21 runs   (    2.09 ms per token,   477.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.41 ms /    14 tokens (   46.53 ms per token,    21.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2194.41 ms /    20 runs   (  109.72 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    3094.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 51%|█████▏    | 54/105 [02:50<02:34,  3.03s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      38.92 ms /    19 runs   (    2.05 ms per token,   488.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.01 ms /    17 tokens (   42.29 ms per token,    23.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1971.13 ms /    18 runs   (  109.51 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    2911.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 52%|█████▏    | 55/105 [02:52<02:13,  2.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.81 ms /     9 runs   (    2.09 ms per token,   478.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     853.50 ms /    22 tokens (   38.80 ms per token,    25.78 tokens per second)\n",
      "llama_print_timings:        eval time =     871.85 ms /     8 runs   (  108.98 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    1831.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 53%|█████▎    | 56/105 [02:53<01:58,  2.41s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      23.54 ms /    11 runs   (    2.14 ms per token,   467.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     568.53 ms /    32 tokens (   17.77 ms per token,    56.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.80 ms /    10 runs   (  110.78 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    1805.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 54%|█████▍    | 57/105 [02:56<01:56,  2.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      31.07 ms /    15 runs   (    2.07 ms per token,   482.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.78 ms /    17 tokens (   42.93 ms per token,    23.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1535.80 ms /    14 runs   (  109.70 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =    2441.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 55%|█████▌    | 58/105 [02:58<01:46,  2.26s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.53 ms /    10 runs   (    2.05 ms per token,   487.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.76 ms /    19 tokens (   40.46 ms per token,    24.72 tokens per second)\n",
      "llama_print_timings:        eval time =     982.02 ms /     9 runs   (  109.11 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    1868.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 56%|█████▌    | 59/105 [03:02<02:08,  2.79s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      53.73 ms /    26 runs   (    2.07 ms per token,   483.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     943.86 ms /    25 tokens (   37.75 ms per token,    26.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2768.99 ms /    25 runs   (  110.76 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    4019.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 57%|█████▋    | 60/105 [03:04<02:00,  2.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      28.79 ms /    14 runs   (    2.06 ms per token,   486.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     797.21 ms /    20 tokens (   39.86 ms per token,    25.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1422.41 ms /    13 runs   (  109.42 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    2386.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 58%|█████▊    | 61/105 [03:07<01:59,  2.71s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      33.52 ms /    16 runs   (    2.10 ms per token,   477.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     958.31 ms /    26 tokens (   36.86 ms per token,    27.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1649.90 ms /    15 runs   (  109.99 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    2795.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 59%|█████▉    | 62/105 [03:09<01:45,  2.46s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.61 ms /    11 runs   (    2.06 ms per token,   486.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.07 ms /    14 tokens (   45.15 ms per token,    22.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.31 ms /    10 runs   (  110.73 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    1873.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 60%|██████    | 63/105 [03:11<01:33,  2.24s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.38 ms /     9 runs   (    2.04 ms per token,   489.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     714.84 ms /    43 tokens (   16.62 ms per token,    60.15 tokens per second)\n",
      "llama_print_timings:        eval time =     880.66 ms /     8 runs   (  110.08 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    1702.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      56.42 ms /    27 runs   (    2.09 ms per token,   478.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     572.36 ms /    32 tokens (   17.89 ms per token,    55.91 tokens per second)\n",
      " 61%|██████    | 64/105 [03:14<01:50,  2.69s/it]llama_print_timings:        eval time =    2862.07 ms /    26 runs   (  110.08 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    3753.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 62%|██████▏   | 65/105 [03:16<01:34,  2.37s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.61 ms /     9 runs   (    2.07 ms per token,   483.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.99 ms /    13 tokens (   48.00 ms per token,    20.83 tokens per second)\n",
      "llama_print_timings:        eval time =     866.88 ms /     8 runs   (  108.36 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    1598.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 63%|██████▎   | 66/105 [03:21<02:03,  3.16s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      69.92 ms /    34 runs   (    2.06 ms per token,   486.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     969.53 ms /    27 tokens (   35.91 ms per token,    27.85 tokens per second)\n",
      "llama_print_timings:        eval time =    3636.56 ms /    33 runs   (  110.20 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    5005.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 64%|██████▍   | 67/105 [03:24<01:53,  2.98s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      37.20 ms /    18 runs   (    2.07 ms per token,   483.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     480.14 ms /     8 tokens (   60.02 ms per token,    16.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1852.64 ms /    17 runs   (  108.98 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    2542.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 65%|██████▍   | 68/105 [03:25<01:36,  2.61s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.85 ms /    10 runs   (    2.09 ms per token,   479.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.59 ms /    15 tokens (   43.51 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:        eval time =     983.87 ms /     9 runs   (  109.32 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =    1754.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 66%|██████▌   | 69/105 [03:27<01:25,  2.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.41 ms /    10 runs   (    2.04 ms per token,   489.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.27 ms /    19 tokens (   40.17 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:        eval time =     974.90 ms /     9 runs   (  108.32 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    1854.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 67%|██████▋   | 70/105 [03:29<01:17,  2.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.47 ms /    10 runs   (    2.05 ms per token,   488.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.83 ms /    41 tokens (   17.09 ms per token,    58.50 tokens per second)\n",
      "llama_print_timings:        eval time =     989.93 ms /     9 runs   (  109.99 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =    1807.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 68%|██████▊   | 71/105 [03:32<01:26,  2.56s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      51.78 ms /    25 runs   (    2.07 ms per token,   482.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     447.47 ms /     7 tokens (   63.92 ms per token,    15.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2608.46 ms /    24 runs   (  108.69 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =    3348.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 69%|██████▊   | 72/105 [03:36<01:31,  2.78s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.87 ms /    19 runs   (    1.84 ms per token,   544.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1055.31 ms /    68 tokens (   15.52 ms per token,    64.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2018.81 ms /    18 runs   (  112.16 ms per token,     8.92 tokens per second)\n",
      "llama_print_timings:       total time =    3299.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 70%|██████▉   | 73/105 [03:38<01:22,  2.58s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.96 ms /    11 runs   (    2.00 ms per token,   500.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     906.97 ms /    24 tokens (   37.79 ms per token,    26.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1084.74 ms /    10 runs   (  108.47 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    2118.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 70%|███████   | 74/105 [03:39<01:10,  2.29s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.27 ms /     9 runs   (    2.03 ms per token,   492.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     624.31 ms /    14 tokens (   44.59 ms per token,    22.42 tokens per second)\n",
      "llama_print_timings:        eval time =     864.58 ms /     8 runs   (  108.07 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    1593.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 71%|███████▏  | 75/105 [03:43<01:18,  2.60s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      42.15 ms /    20 runs   (    2.11 ms per token,   474.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     996.89 ms /    27 tokens (   36.92 ms per token,    27.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2096.12 ms /    19 runs   (  110.32 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    3329.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 72%|███████▏  | 76/105 [03:47<01:26,  2.99s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      60.45 ms /    29 runs   (    2.08 ms per token,   479.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     471.58 ms /     8 tokens (   58.95 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =    3063.56 ms /    28 runs   (  109.41 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    3876.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 73%|███████▎  | 77/105 [03:48<01:13,  2.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.87 ms /    10 runs   (    2.09 ms per token,   479.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.92 ms /    16 tokens (   42.81 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:        eval time =     974.99 ms /     9 runs   (  108.33 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    1778.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 74%|███████▍  | 78/105 [03:50<01:03,  2.36s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.35 ms /    10 runs   (    2.04 ms per token,   491.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.37 ms /    34 tokens (   19.01 ms per token,    52.60 tokens per second)\n",
      "llama_print_timings:        eval time =     985.28 ms /     9 runs   (  109.48 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1747.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 75%|███████▌  | 79/105 [03:52<01:01,  2.37s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      34.86 ms /    17 runs   (    2.05 ms per token,   487.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     450.31 ms /     7 tokens (   64.33 ms per token,    15.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1740.99 ms /    16 runs   (  108.81 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =    2390.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 76%|███████▌  | 80/105 [03:56<01:06,  2.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      50.57 ms /    24 runs   (    2.11 ms per token,   474.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     557.64 ms /    11 tokens (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2504.88 ms /    23 runs   (  108.91 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    3350.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 77%|███████▋  | 81/105 [03:58<00:57,  2.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.23 ms /    10 runs   (    2.02 ms per token,   494.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.84 ms /    16 tokens (   42.68 ms per token,    23.43 tokens per second)\n",
      "llama_print_timings:        eval time =     977.30 ms /     9 runs   (  108.59 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    1778.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 78%|███████▊  | 82/105 [04:00<00:52,  2.28s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.48 ms /    10 runs   (    1.95 ms per token,   513.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.91 ms /    62 tokens (   13.95 ms per token,    71.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1000.44 ms /     9 runs   (  111.16 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    1981.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 79%|███████▉  | 83/105 [04:11<01:47,  4.91s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     173.11 ms /    85 runs   (    2.04 ms per token,   491.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.92 ms /    35 tokens (   18.68 ms per token,    53.52 tokens per second)\n",
      "llama_print_timings:        eval time =    9380.94 ms /    84 runs   (  111.68 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =   11034.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 80%|████████  | 84/105 [04:14<01:32,  4.40s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      44.56 ms /    21 runs   (    2.12 ms per token,   471.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.66 ms /    18 tokens (   41.09 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:        eval time =    2221.37 ms /    20 runs   (  111.07 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =    3217.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 81%|████████  | 85/105 [04:16<01:13,  3.67s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.93 ms /    13 runs   (    2.07 ms per token,   482.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     503.25 ms /     9 tokens (   55.92 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1301.57 ms /    12 runs   (  108.46 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    1958.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 82%|████████▏ | 86/105 [04:18<00:59,  3.12s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.53 ms /    11 runs   (    2.05 ms per token,   488.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.69 ms /    14 tokens (   44.34 ms per token,    22.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1085.20 ms /    10 runs   (  108.52 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    1833.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 83%|████████▎ | 87/105 [04:22<01:02,  3.47s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      52.62 ms /    25 runs   (    2.10 ms per token,   475.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1269.62 ms /    96 tokens (   13.23 ms per token,    75.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2709.67 ms /    24 runs   (  112.90 ms per token,     8.86 tokens per second)\n",
      "llama_print_timings:       total time =    4271.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 84%|████████▍ | 88/105 [04:25<00:59,  3.48s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      51.48 ms /    25 runs   (    2.06 ms per token,   485.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     621.29 ms /    14 tokens (   44.38 ms per token,    22.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2604.23 ms /    24 runs   (  108.51 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    3512.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 85%|████████▍ | 89/105 [04:27<00:48,  3.03s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.57 ms /    10 runs   (    2.06 ms per token,   486.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     862.64 ms /    63 tokens (   13.69 ms per token,    73.03 tokens per second)\n",
      "llama_print_timings:        eval time =     992.74 ms /     9 runs   (  110.30 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =    1969.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 86%|████████▌ | 90/105 [04:30<00:41,  2.74s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      20.59 ms /    10 runs   (    2.06 ms per token,   485.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     955.71 ms /    27 tokens (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_print_timings:        eval time =     982.54 ms /     9 runs   (  109.17 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    2051.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 87%|████████▋ | 91/105 [04:31<00:33,  2.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.48 ms /     9 runs   (    2.05 ms per token,   486.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.92 ms /    17 tokens (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:        eval time =     859.44 ms /     8 runs   (  107.43 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    1653.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 88%|████████▊ | 92/105 [04:38<00:46,  3.60s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      97.62 ms /    48 runs   (    2.03 ms per token,   491.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.15 ms /    16 tokens (   42.01 ms per token,    23.80 tokens per second)\n",
      "llama_print_timings:        eval time =    5125.98 ms /    47 runs   (  109.06 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    6352.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 89%|████████▊ | 93/105 [04:46<01:01,  5.16s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     138.66 ms /    68 runs   (    2.04 ms per token,   490.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.38 ms /    16 tokens (   42.34 ms per token,    23.62 tokens per second)\n",
      "llama_print_timings:        eval time =    7341.35 ms /    67 runs   (  109.57 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    8804.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      " 90%|████████▉ | 94/105 [04:51<00:55,  5.01s/it]llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      69.15 ms /    34 runs   (    2.03 ms per token,   491.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.54 ms /    36 tokens (   18.21 ms per token,    54.92 tokens per second)\n",
      "llama_print_timings:        eval time =    3621.35 ms /    33 runs   (  109.74 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    4664.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 90%|█████████ | 95/105 [04:53<00:40,  4.08s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      24.19 ms /    12 runs   (    2.02 ms per token,   496.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     575.81 ms /    12 tokens (   47.98 ms per token,    20.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1190.38 ms /    11 runs   (  108.22 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =    1904.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 91%|█████████▏| 96/105 [04:57<00:36,  4.10s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      53.30 ms /    26 runs   (    2.05 ms per token,   487.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.03 ms /    31 tokens (   35.00 ms per token,    28.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2735.37 ms /    25 runs   (  109.41 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    4118.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 92%|█████████▏| 97/105 [04:59<00:27,  3.44s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      21.93 ms /    11 runs   (    1.99 ms per token,   501.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.07 ms /    38 tokens (   17.76 ms per token,    56.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.83 ms /    10 runs   (  109.58 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1896.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 93%|█████████▎| 98/105 [05:09<00:37,  5.39s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =     153.46 ms /    75 runs   (    2.05 ms per token,   488.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     905.99 ms /    25 tokens (   36.24 ms per token,    27.59 tokens per second)\n",
      "llama_print_timings:        eval time =    8185.05 ms /    74 runs   (  110.61 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    9954.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 94%|█████████▍| 99/105 [05:11<00:25,  4.27s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.51 ms /     9 runs   (    2.06 ms per token,   486.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.03 ms /    39 tokens (   17.33 ms per token,    57.69 tokens per second)\n",
      "llama_print_timings:        eval time =     869.43 ms /     8 runs   (  108.68 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =    1646.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 95%|█████████▌| 100/105 [05:15<00:21,  4.29s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      55.10 ms /    28 runs   (    1.97 ms per token,   508.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.02 ms /    30 tokens (   34.83 ms per token,    28.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2954.66 ms /    27 runs   (  109.43 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =    4318.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 96%|█████████▌| 101/105 [05:17<00:14,  3.62s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      18.13 ms /     9 runs   (    2.01 ms per token,   496.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1067.55 ms /    68 tokens (   15.70 ms per token,    63.70 tokens per second)\n",
      "llama_print_timings:        eval time =     886.98 ms /     8 runs   (  110.87 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    2058.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 97%|█████████▋| 102/105 [05:19<00:09,  3.21s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      22.65 ms /    14 runs   (    1.62 ms per token,   618.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.92 ms /    38 tokens (   17.76 ms per token,    56.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1425.02 ms /    13 runs   (  109.62 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =    2255.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 98%|█████████▊| 103/105 [05:20<00:05,  2.63s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /     6 runs   (    2.05 ms per token,   487.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.41 ms /    34 tokens (   19.13 ms per token,    52.27 tokens per second)\n",
      "llama_print_timings:        eval time =     550.59 ms /     5 runs   (  110.12 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =    1269.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      " 99%|█████████▉| 104/105 [05:22<00:02,  2.42s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      26.56 ms /    13 runs   (    2.04 ms per token,   489.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     473.78 ms /     8 tokens (   59.22 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1297.59 ms /    12 runs   (  108.13 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    1919.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "100%|██████████| 105/105 [05:24<00:00,  2.22s/it]\n",
      "llama_print_timings:        load time =    5159.54 ms\n",
      "llama_print_timings:      sample time =      19.66 ms /    10 runs   (    1.97 ms per token,   508.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.20 ms /    34 tokens (   19.09 ms per token,    52.37 tokens per second)\n",
      "llama_print_timings:        eval time =     988.66 ms /     9 runs   (  109.85 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    1753.26 ms\n",
      "100%|██████████| 105/105 [05:24<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "for key in dfs:\n",
    "    responses = []\n",
    "    reasons = []\n",
    "    prompts = [prompt + message for message in dfs[key][key.replace('_retry', '')].to_list()]\n",
    "\n",
    "    for prompt in tqdm(prompts):\n",
    "        result = llm(prompt, max_tokens=128, echo=False)\n",
    "        responses.append(result['choices'][0]['text'].strip())\n",
    "        reasons.append(result['choices'][0]['finish_reason'])\n",
    "    dfs[key] = dfs[key].with_columns(responses=pl.Series(responses), reasons=pl.Series(reasons))\n",
    "    dfs[key].write_parquet(f'{key}.parquet')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7312500,
     "sourceId": 11677981,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 159451933,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1799.533016,
   "end_time": "2025-05-05T00:00:59.096912",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-04T23:30:59.563896",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "035e60ca350d40d991b4b0abff4de6dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ee994650b8bc430893080710f0ec9f97",
       "max": 8543114368.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aa4799369f734559bf1d7920638a8fb1",
       "value": 8543114368.0
      }
     },
     "06fe7cbac9cd4b01ab419ee64160bcec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e51e53af9078476cae43cc07fd712dc2",
       "placeholder": "​",
       "style": "IPY_MODEL_e372a7b6a69e4c339b304c6f9796dc8f",
       "value": "YandexGPT-5-Lite-8B-instruct.Q8_0.gguf: 100%"
      }
     },
     "15be8c06376d4aeabc7dbee9bf7238d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a4879219dd4f48ad8c34da2a167db625",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_383fccba35d84d8eb8a4094b771452e3",
       "value": 1.0
      }
     },
     "2fefa22354884e85a4f56f0b34cb5f44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "383fccba35d84d8eb8a4094b771452e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6bc5cce1ad464d49b11670c3f4bfedfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f269e320d26e498b905aed110c910f44",
        "IPY_MODEL_15be8c06376d4aeabc7dbee9bf7238d2",
        "IPY_MODEL_cc2ff5a48111422fb3a43862228361d0"
       ],
       "layout": "IPY_MODEL_ef0efbdfd87d494bbcfc24dc48f8a08a"
      }
     },
     "a38329d755bd4e71aed36aa7c5b2be56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4879219dd4f48ad8c34da2a167db625": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa4799369f734559bf1d7920638a8fb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "acada2336dec481f89352fefc5e7adad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b55c4218eae54a198dc79b4f5b61e90b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c313843634cf4e9e90e269df2409213c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cbffcd01b18648ca8aa5e6089df3ead1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc2ff5a48111422fb3a43862228361d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cbffcd01b18648ca8aa5e6089df3ead1",
       "placeholder": "​",
       "style": "IPY_MODEL_acada2336dec481f89352fefc5e7adad",
       "value": " 1/1 [01:04&lt;00:00, 64.81s/it]"
      }
     },
     "d677f064379648c296b0b6637c38c5f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_06fe7cbac9cd4b01ab419ee64160bcec",
        "IPY_MODEL_035e60ca350d40d991b4b0abff4de6dd",
        "IPY_MODEL_de674c7f9a684d30afa1b2e490e3ba8b"
       ],
       "layout": "IPY_MODEL_b55c4218eae54a198dc79b4f5b61e90b"
      }
     },
     "d81037a66e484e53acfdd582257fb018": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "de674c7f9a684d30afa1b2e490e3ba8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a38329d755bd4e71aed36aa7c5b2be56",
       "placeholder": "​",
       "style": "IPY_MODEL_d81037a66e484e53acfdd582257fb018",
       "value": " 8.54G/8.54G [00:22&lt;00:00, 251MB/s]"
      }
     },
     "e372a7b6a69e4c339b304c6f9796dc8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e51e53af9078476cae43cc07fd712dc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee994650b8bc430893080710f0ec9f97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef0efbdfd87d494bbcfc24dc48f8a08a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f269e320d26e498b905aed110c910f44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2fefa22354884e85a4f56f0b34cb5f44",
       "placeholder": "​",
       "style": "IPY_MODEL_c313843634cf4e9e90e269df2409213c",
       "value": "Fetching 1 files: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
